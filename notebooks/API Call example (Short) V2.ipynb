{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb8344e0-0b22-495a-bba2-402284e4e8b0",
   "metadata": {},
   "source": [
    "# MISO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9062964d-4e9e-442b-bf01-bc7376326e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, json\n",
    "import pandas as pd\n",
    "from datetime import datetime, date, timedelta\n",
    "import time\n",
    "import sys, os\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import wget\n",
    "import urllib\n",
    "import warnings\n",
    "import requests\n",
    "\n",
    "\n",
    "start_time = input('Enter the start time(YYYY-MM-DD): ')\n",
    "if len(start_time) < 1:\n",
    "    start_time = '2025-01-01'\n",
    "\n",
    "end_time = input('Enter the end time(YYYY-MM-DD): ')\n",
    "if len(end_time) < 1:\n",
    "    end_time = '2025-01-02'\n",
    "\n",
    "variable_name = input('Enter the Variable name: ')\n",
    "if len(variable_name) < 1:\n",
    "    variable_name = 'demand_forecast_hourly_regional_MISO'\n",
    "\n",
    "info_dict_MISO = {\n",
    "    'solar_forecast_hourly_MISO':{'variable_str':'_mom.xlsx','variable_date_str':'SOLAR HOURLY'},\n",
    "    'wind_forecast_hourly_MISO':{'variable_str':'_mom.xlsx','variable_date_str':'WIND HOURLY'},\n",
    "    'outage_forecast_daily_MISO':{'variable_str':'_mom.xlsx','variable_date_str':'OUTAGE'},\n",
    "    'demand_forecast_hourly_zone_MISO':{'variable_str':'df_al.xls','variable_date_str':'n/a'},\n",
    "    'demand_forecast_hourly_regional_MISO':{'variable_str':'rf_al.xls','variable_date_str':'n/a'},\n",
    "    'DA_LMP_MISO':{'variable_str':'da_exante_lmp.csv','variable_date_str':'n/a'},# Miso will change it to New API\n",
    "    'RT_LMP_MISO':{'variable_str':'5min_exante_lmp.xlsx','variable_date_str':'n/a'},# Miso will change it to New API\n",
    "    'DA_HUB_price_MISO': {'variable_str': 'da_pr.xls','variable_date_str':'n/a'},\n",
    "    'RT_HUB_price_MISO': {'variable_str': 'rt_pr.xls','variable_date_str':'n/a'},\n",
    "    }\n",
    "\n",
    "def date_range_list(start_date, end_date, days_num=1):\n",
    "    # Return generator for a list datetime.date objects (inclusive) between start_date and end_date (inclusive).\n",
    "    curr_date = start_date\n",
    "    while curr_date <= end_date:\n",
    "        yield curr_date \n",
    "        curr_date += timedelta(days=days_num)\n",
    "\n",
    "\n",
    "def miso_data_downloading(start_time, end_time, variable_name, info_dict_MISO):\n",
    "    start_time_list = start_time.split('-')\n",
    "    end_time_list = end_time.split('-')\n",
    "\n",
    "    d0 = date(int(start_time_list[0]), int(start_time_list[1]), int(start_time_list[2]))\n",
    "    d1 = date(int(end_time_list[0]), int(end_time_list[1]), int(end_time_list[2]))\n",
    "    data_array = []\n",
    "    date_list = date_range_list(d0, d1)\n",
    "\n",
    "    variable_str = info_dict_MISO[variable_name]['variable_str']\n",
    "    variable_date_str = info_dict_MISO[variable_name]['variable_date_str']\n",
    "    \n",
    "    ###\n",
    "    # variable_name=='DA_HUB_price_MISO' or variable_name=='RT_LMP_MISO'\n",
    "    ###\n",
    "    if variable_name=='DA_HUB_price_MISO' or variable_name=='RT_LMP_MISO':\n",
    "        for day in date_list:\n",
    "            date_list = str(day).split('-')\n",
    "            YYYYMMDD = date_list[0]+date_list[1]+date_list[2]\n",
    "            url = 'https://docs.misoenergy.org/marketreports/'+ YYYYMMDD +'_' + variable_str\n",
    "\n",
    "            df_0 = pd.read_excel(url, index_col=None,na_values=['NA'], usecols=\"B\")\n",
    "            #print(df_0)\n",
    "            header_num = 0\n",
    "            header = 0\n",
    "            Header_str = 'NaN'\n",
    "            while Header_str != 'MISO System':\n",
    "                Header_str = str(df_0.iloc[header,0])\n",
    "                header = header_num\n",
    "                header_num = header_num + 1\n",
    "                if header > len(df_0['Unnamed: 1']):\n",
    "                    break\n",
    "            #print(header)\n",
    "            df = pd.read_excel(io = url,index_col= None , na_values=['NA'], header=header, nrows = 24)#, usecols=[\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\"]\n",
    "            print(df)\n",
    "            if str(day) == str(start_time):\n",
    "                sum_df = df\n",
    "            else:\n",
    "                sum_df = pd.concat([sum_df, df], ignore_index = True)\n",
    "\n",
    "    \n",
    "    \n",
    "    ###\n",
    "    # elif (variable_name == 'solar_forecast_hourly_MISO' or variable_name == 'wind_forecast_hourly_MISO' or variable_name == 'outage_forecast_daily_MISO')\n",
    "    ###\n",
    "    elif (variable_name == 'solar_forecast_hourly_MISO' or variable_name == 'wind_forecast_hourly_MISO' \n",
    "          or variable_name == 'outage_forecast_daily_MISO'):\n",
    "        i = 0\n",
    "        for day in date_list:\n",
    "            date_str = str(day).split('-')\n",
    "            YYYYMMDD = date_str[0]+date_str[1]+date_str[2]\n",
    "            current_date = day + timedelta(days = 1)\n",
    "            current_date_str = str(current_date).split('-')\n",
    "            \n",
    "            url_2 = 'https://docs.misoenergy.org/marketreports/'+ YYYYMMDD + '_'+variable_str\n",
    "            print(YYYYMMDD)\n",
    "            header = 0\n",
    "            try:\n",
    "                df = pd.read_excel(url_2, index_col=None, sheet_name=variable_date_str,na_values=['NA'], usecols=\"A\")\n",
    "                header_num = 0\n",
    "                header = 0\n",
    "                Header_str = 'NaN'\n",
    "                while Header_str != 'DAY HE' and Header_str != 'Day HE':#or Header_str != 'Day HE'\n",
    "                    Header_str = str(df.iloc[header,0])\n",
    "                    header = header_num\n",
    "                    header_num = header_num + 1\n",
    "                    if header > len(df['Unnamed: 0']):\n",
    "                        break\n",
    "                df_mom = pd.read_excel(io = url_2,index_col= None , na_values=['NA'], header=header, usecols='A,B,C,D',#,D\n",
    "                                     sheet_name=variable_date_str,nrows = 48,engine=\"openpyxl\")\n",
    "                time_info = 'NaN'\n",
    "                time_info_1am = current_date_str[1] + '/'+ current_date_str[2] + '/' + current_date_str[0] + ' 1'\n",
    "                time_info_7am = current_date_str[1] + '/'+ current_date_str[2] + '/' + current_date_str[0] + ' 7'\n",
    "                \n",
    "                time_idx = 0\n",
    "                while time_info != time_info_1am:\n",
    "                    time_info = str(''.join(list(df_mom.iloc[time_idx,0])[2:15]))\n",
    "                    time_idx = time_idx + 1\n",
    "                    #if time_info = \n",
    "                    if time_idx > len(df_mom.iloc[:,0]):\n",
    "                        break\n",
    "                iloc_start = time_idx - 1\n",
    "                iloc_end = iloc_start+24\n",
    "                \n",
    "                \n",
    "                df_mom = df_mom.iloc[iloc_start:iloc_end,:]\n",
    "                data_array.append(1)\n",
    "            except:\n",
    "                try:\n",
    "                    df = pd.read_excel(url_1, index_col=None, sheet_name=variable_date_str,na_values=['NA'], usecols=\"A\")\n",
    "                    header_num = 0\n",
    "                    header = 0\n",
    "                    Header_str = 'NaN'\n",
    "                    while Header_str != 'DAY HE'and Header_str != 'Day HE':#or Header_str != 'Day HE'\n",
    "                        Header_str = str(df.iloc[header,0])\n",
    "                        header = header_num\n",
    "                        header_num = header_num + 1\n",
    "                        if header > len(df['Unnamed: 0']):\n",
    "                            break\n",
    "        \n",
    "                    df_mom = pd.read_excel(io = url_1,index_col= None , na_values=['NA'], header=header, usecols='A,B,C,D',#,D\n",
    "                                     sheet_name=variable_date_str,nrows = 168,engine=\"openpyxl\")\n",
    "                    time_info = 'NaN'\n",
    "                    time_info_1am = current_date_str[1] + '/'+ current_date_str[2] + '/' + current_date_str[0] + ' 1'\n",
    "                    time_info_7am = current_date_str[1] + '/'+ current_date_str[2] + '/' + current_date_str[0] + ' 7'\n",
    "        \n",
    "                    time_idx = 0\n",
    "                    while time_info != time_info_1am:\n",
    "                        time_info = str(''.join(list(df_mom.iloc[time_idx,0])[2:15]))\n",
    "                        time_idx = time_idx + 1\n",
    "                        if time_idx > len(df_mom.iloc[:,0]):\n",
    "                            break\n",
    "                    iloc_start = time_idx - 1\n",
    "                    iloc_end = iloc_start+24\n",
    "        \n",
    "                    df_mom = df_mom.iloc[iloc_start:iloc_end,:]\n",
    "                    data_array.append(2)\n",
    "            \n",
    "                except:\n",
    "                    intial_date = date(int(date_str[0]), int(date_str[1]), int(date_str[2]))\n",
    "                    day_i = 0\n",
    "                    #day_i = day_i + 1\n",
    "                    file_date = intial_date + timedelta(days = -day_i)\n",
    "                    file_date_str = str(file_date).split('-')\n",
    "                    YYYYMMDD_1 = file_date_str[0]+file_date_str[1]+file_date_str[2]\n",
    "                    url_try = 'https://docs.misoenergy.org/marketreports/'+ YYYYMMDD_1 + variable_str\n",
    "        \n",
    "                    response = requests.get(url_try)\n",
    "                    while response.status_code != 200:\n",
    "                        file_date = intial_date + timedelta(days = -day_i)\n",
    "                        file_date_str = str(file_date).split('-')\n",
    "                        YYYYMMDD_1 = file_date_str[0]+file_date_str[1]+file_date_str[2]\n",
    "                        url_try = 'https://docs.misoenergy.org/marketreports/'+ YYYYMMDD_1 + variable_str\n",
    "                        response = requests.get(url_try)\n",
    "                        day_i = day_i + 1\n",
    "                        print(\"Found previous: \", YYYYMMDD_1)\n",
    "                    #url_1_1 = 'https://docs.misoenergy.org/marketreports/'+ YYYYMMDD + '_mom.xlsx'\n",
    "                    df = pd.read_excel(url_try, index_col=None, sheet_name='WIND HOURLY',na_values=['NA'], usecols=\"A\")\n",
    "                    header_num = 0\n",
    "                    header = 0\n",
    "                    Header_str = 'NaN'\n",
    "                    while Header_str != 'DAY HE'and Header_str != 'Day HE':#or Header_str != 'Day HE'\n",
    "                        Header_str = str(df.iloc[header,0])\n",
    "                        header = header_num\n",
    "                        header_num = header_num + 1\n",
    "                        if header > len(df['Unnamed: 0']):\n",
    "                            break\n",
    "        \n",
    "                    df_mom = pd.read_excel(io = url_try,index_col= None , na_values=['NA'], header=header, usecols='A,B,C,D',#,D\n",
    "                                     sheet_name='WIND HOURLY',nrows = 168,engine=\"openpyxl\")\n",
    "                    time_info = 'NaN'\n",
    "                    time_info_1am = current_date_str[1] + '/'+ current_date_str[2] + '/' + current_date_str[0] + ' 1'\n",
    "                    time_info_7am = current_date_str[1] + '/'+ current_date_str[2] + '/' + current_date_str[0] + ' 7'\n",
    "        \n",
    "                    time_idx = 0\n",
    "                    while time_info != time_info_1am:\n",
    "                        time_info = str(''.join(list(df_mom.iloc[time_idx,0])[2:15]))\n",
    "                        time_idx = time_idx + 1\n",
    "                        if time_idx > len(df_mom.iloc[:,0]):\n",
    "                            break\n",
    "                    iloc_start = time_idx - 1\n",
    "                    iloc_end = iloc_start+24\n",
    "        \n",
    "                    df_mom = df_mom.iloc[iloc_start:iloc_end,:]\n",
    "                    data_array.append(2)\n",
    "                if Header_str == 'Day HE':\n",
    "                    df_mom = df_mom.rename(columns={'Day HE': 'DAY HE', 'North': 'North','Central': 'Central'})\n",
    "            \n",
    "            if str(day) == str(start_time):\n",
    "                sum_df = df_mom\n",
    "            else:\n",
    "                sum_df = pd.concat([sum_df, df_mom], ignore_index = False)#, ignore_index = True\n",
    "            url_1 = url_2\n",
    "            i = i + 1\n",
    "    ###\n",
    "    # elif (variable_name == 'outage_forecast_daily_MISO')\n",
    "    ###\n",
    "    elif (variable_name == 'outage_forecast_daily_MISO'):\n",
    "        i = 0\n",
    "        for day in date_list:\n",
    "            date_str = str(day).split('-')\n",
    "            YYYYMMDD = date_str[0]+date_str[1]+date_str[2]\n",
    "            current_date = day + timedelta(days = 1)\n",
    "            current_date_str = str(current_date).split('-')\n",
    "            \n",
    "            url_2 = 'https://docs.misoenergy.org/marketreports/'+ YYYYMMDD + '_' + variable_str\n",
    "            print(YYYYMMDD)\n",
    "            header = 0\n",
    "            try:\n",
    "                #df = pd.read_excel(url_2, index_col=None, sheet_name='OUTAGE',na_values=['NA'], usecols=\"C\")\n",
    "                #header_num = 0\n",
    "                header = 6\n",
    "                index_day = 2\n",
    "                df_outage = pd.read_excel(io = url_2,index_col= None , na_values=['NA'], header=header, usecols='A,B,C',#,D\n",
    "                                     sheet_name=variable_date_str,nrows = 16,engine=\"openpyxl\")\n",
    "                \n",
    "                sum_north = df_outage[df_outage[\"Unnamed: 0\"]==\"North\"].sum()\n",
    "                sum_central = df_outage[df_outage[\"Unnamed: 0\"]==\"Central\"].sum()\n",
    "                sum_south = df_outage[df_outage[\"Unnamed: 0\"]==\"South\"].sum()\n",
    "                sum_miso = df_outage[df_outage[\"Unnamed: 0\"]==\"MISO\"].sum()\n",
    "                df_sum_data_day =  pd.DataFrame({'Outage_North': [sum_north.iloc[index_day]],'Outage_Central': [sum_central.iloc[index_day]],\n",
    "                               'Outage_South': [sum_south.iloc[index_day]],'Outage_MISO': [sum_miso.iloc[index_day]]})\n",
    "                df_outage_sum = pd.DataFrame()\n",
    "                for i_hour in range(24):\n",
    "                    df_outage_sum = pd.concat([df_sum_data_day, df_outage_sum], ignore_index = False)\n",
    "                \n",
    "                data_array.append(1)\n",
    "            except:\n",
    "                try:\n",
    "                    #df = pd.read_excel(url_1, index_col=None, sheet_name='SOLAR HOURLY',na_values=['NA'], usecols=\"A,B,C,D\")\n",
    "                    header_num = 0\n",
    "                    header = 6\n",
    "                    \n",
    "                    df_outage = pd.read_excel(io = url_1,index_col= None , na_values=['NA'], header=header, usecols='A,B,C,D',#,D\n",
    "                                     sheet_name=variable_date_str,nrows = 16,engine=\"openpyxl\")\n",
    "                    index_day = 3\n",
    "                    sum_north = df_outage[df_outage[\"Unnamed: 0\"]==\"North\"].sum()\n",
    "                    sum_central = df_outage[df_outage[\"Unnamed: 0\"]==\"Central\"].sum()\n",
    "                    sum_south = df_outage[df_outage[\"Unnamed: 0\"]==\"South\"].sum()\n",
    "                    sum_miso = df_outage[df_outage[\"Unnamed: 0\"]==\"MISO\"].sum()\n",
    "                    df_sum_data_day =  pd.DataFrame({'Outage_North': [sum_north.iloc[index_day]],'Outage_Central': [sum_central.iloc[index_day]],\n",
    "                               'Outage_South': [sum_south.iloc[index_day]],'Outage_MISO': [sum_miso.iloc[index_day]]})\n",
    "                    df_outage_sum = pd.DataFrame()\n",
    "                    for i_hour in range(24):\n",
    "                        df_outage_sum = pd.concat([df_sum_data_day, df_outage_sum], ignore_index = False)\n",
    "                    data_array.append(2)\n",
    "            \n",
    "                except:\n",
    "                    print(\"Can not find: \", YYYYMMDD)\n",
    "                    intial_date = date(int(date_str[0]), int(date_str[1]), int(date_str[2]))\n",
    "                    day_i = 0\n",
    "                    #day_i = day_i + 1\n",
    "                    file_date = intial_date + timedelta(days = -day_i)\n",
    "                    file_date_str = str(file_date).split('-')\n",
    "                    YYYYMMDD_1 = file_date_str[0]+file_date_str[1]+file_date_str[2]\n",
    "                    url_try = 'https://docs.misoenergy.org/marketreports/'+ YYYYMMDD_1+ '_'+variable_str\n",
    "        \n",
    "                    response = requests.get(url_try)\n",
    "                    while response.status_code != 200:\n",
    "                        file_date = intial_date + timedelta(days = -day_i)\n",
    "                        file_date_str = str(file_date).split('-')\n",
    "                        YYYYMMDD_1 = file_date_str[0]+file_date_str[1]+file_date_str[2]\n",
    "                        url_try = 'https://docs.misoenergy.org/marketreports/'+ YYYYMMDD_1 + '_' + variable_str\n",
    "                        response = requests.get(url_try)\n",
    "                        day_i = day_i + 1\n",
    "                    #print(\"Found previous: \", YYYYMMDD_1)\n",
    "                    #url_1_1 = 'https://docs.misoenergy.org/marketreports/'+ YYYYMMDD + '_mom.xlsx'\n",
    "                    #df = pd.read_excel(url_try, index_col=None, sheet_name='OUTAGE',na_values=['NA'], usecols=\"A,B,C,D,E,F,G,H,I\")\n",
    "                    header = 6\n",
    "                    \n",
    "                    df_outage = pd.read_excel(io = url_try,index_col= None , na_values=['NA'], header=header, usecols=\"A,B,C,D,E,F,G,H,I\",#,D\n",
    "                                     sheet_name=variable_date_str,nrows = 16,engine=\"openpyxl\")\n",
    "                    index_day = day_i+1\n",
    "                    print(\"!!!!!\",index_day)\n",
    "                    \n",
    "                    sum_north = df_outage[df_outage[\"Unnamed: 0\"]==\"North\"].sum()\n",
    "                    sum_central = df_outage[df_outage[\"Unnamed: 0\"]==\"Central\"].sum()\n",
    "                    sum_south = df_outage[df_outage[\"Unnamed: 0\"]==\"South\"].sum()\n",
    "                    sum_miso = df_outage[df_outage[\"Unnamed: 0\"]==\"MISO\"].sum()\n",
    "                    df_sum_data_day =  pd.DataFrame({'Outage_North': [sum_north.iloc[index_day]],'Outage_Central': [sum_central.iloc[index_day]],\n",
    "                               'Outage_South': [sum_south.iloc[index_day]],'Outage_MISO': [sum_miso.iloc[index_day]]})\n",
    "                    df_outage_sum = pd.DataFrame()\n",
    "                    for i_hour in range(24):\n",
    "                        df_outage_sum = pd.concat([df_sum_data_day, df_outage_sum], ignore_index = False)\n",
    "                    print(df_outage_sum)\n",
    "                data_array.append(2)\n",
    "                \n",
    "            \n",
    "            if str(day) == str(start_time):\n",
    "                sum_df = df_outage_sum\n",
    "            else:\n",
    "                sum_df = pd.concat([sum_df, df_outage_sum], ignore_index = False)#, ignore_index = True\n",
    "            url_1 = url_2\n",
    "            i = i + 1\n",
    "    ###\n",
    "    # elif (variable_name == 'demand_forecast_hourly_zone_MISO')\n",
    "    ###\n",
    "    elif variable_name == 'demand_forecast_hourly_zone_MISO':\n",
    "        for day in date_list:\n",
    "            date_list = str(day).split('-')\n",
    "            YYYYMMDD = date_list[0]+date_list[1]+date_list[2]\n",
    "            url = 'https://docs.misoenergy.org/marketreports/'+ YYYYMMDD + '_' + variable_str\n",
    "        \n",
    "            df = pd.read_excel(io = url,index_col= None , na_values=['NA'], \n",
    "                               header=None, skiprows = [i for i in (range(32))], nrows = 24).drop([3,5,7,9,11,13,15], axis=1)#, usecols=[\"C\",\"E\",\"G\",\"I\",\"K\",\"M\",\"O\"]\n",
    "            df.rename(columns={0: 'Date', 1: 'Hour', 2: 'Zone1', 4: 'Zone2_7', 6: 'Zone3_5', 8: 'Zone4', 10: 'Zone6', 12: 'Zone8_9', 14: 'MISO'}, inplace=True)#print(day)\n",
    "            #print(df)\n",
    "            if str(day) == str(start_time):\n",
    "                sum_df = df\n",
    "            else:\n",
    "                sum_df = pd.concat([sum_df, df], ignore_index = True)\n",
    "\n",
    "    ###\n",
    "    # elif (variable_name == 'demand_forecast_hourly_zone_MISO')\n",
    "    ###\n",
    "    elif (variable_name == 'demand_forecast_hourly_regional_MISO'):\n",
    "        for day in date_list:\n",
    "            date_list = str(day).split('-')\n",
    "            YYYYMMDD = date_list[0]+date_list[1]+date_list[2]\n",
    "            url = 'https://docs.misoenergy.org/marketreports/'+ YYYYMMDD + '_' + variable_str\n",
    "    \n",
    "            df = pd.read_excel(io = url,index_col= None , na_values=['NA'],# North - D; Central - F; MISO - J\n",
    "                               header=None, skiprows = [i for i in (range(34))], nrows = 24).drop([0, 4,6,8,10], axis=1)\n",
    "            df.rename(columns={1: 'Date', 2: 'Hour', 3: 'North', 5: 'Central', 7: 'South', 9: 'MISO'}, inplace=True)\n",
    "            #print(day)\n",
    "            if str(day) == str(start_time):\n",
    "                sum_df = df\n",
    "            else:\n",
    "                sum_df = pd.concat([sum_df, df], ignore_index = True)\n",
    "        \n",
    "    return sum_df\n",
    "\n",
    "\n",
    "sum_df = miso_data_downloading(start_time, end_time, variable_name, info_dict_MISO)\n",
    "print(sum_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f473ed01-f8a7-484c-8db7-a1349fac3153",
   "metadata": {},
   "source": [
    "# PJM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59349543-5957-4087-8105-fb34d180a58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta,date\n",
    "import time\n",
    "import random\n",
    "\n",
    "start_time = input('Enter the start time(YYYY-MM-DD): ')\n",
    "if len(start_time) < 1:\n",
    "    start_time = '2024-01-01'\n",
    "\n",
    "end_time = input('Enter the end time(YYYY-MM-DD): ')\n",
    "if len(end_time) < 1:\n",
    "    end_time = '2025-10-01'\n",
    "\n",
    "variable_name = input('Enter the Variable name: ')\n",
    "if len(variable_name) < 1:\n",
    "    variable_name = 'demand_forecast_hourly_PJM'\n",
    "\n",
    "info_dict_PJM = {'solar_forecast_5min_PJM':{'variable_str':'five_min_solar_power_forecast','variable_date_str':'datetime_beginning_utc'},\n",
    "    'solar_forecast_hourly_PJM':{'variable_str':'hourly_solar_power_forecast','variable_date_str':'datetime_beginning_utc'},\n",
    "    'wind_forecast_5min_PJM':{'variable_str':'five_min_wind_power_forecast','variable_date_str':'datetime_beginning_utc'},\n",
    "    'wind_forecast_hourly_PJM':{'variable_str':'hourly_wind_power_forecast','variable_date_str':'datetime_beginning_utc'},\n",
    "    'outage_forecast_daily_PJM':{'variable_str':'frcstd_gen_outages','variable_date_str':'forecast_date'},\n",
    "    'demand_forecast_hourly_PJM':{'variable_str':'load_frcstd_hist','variable_date_str':'forecast_hour_beginning_utc'},\n",
    "    'DA_LMP_PJM':{'variable_str':'da_hrl_lmps','variable_date_str':'datetime_beginning_utc'},\n",
    "    'RT_LMP_PJM':{'variable_str':'rt_fivemin_mnt_lmps','variable_date_str':'datetime_beginning_utc'},\n",
    "    }\n",
    "def date_range_list(start_date, end_date, days_num=1):\n",
    "    # Return generator for a list datetime.date objects (inclusive) between start_date and end_date (inclusive).\n",
    "    curr_date = start_date\n",
    "    while curr_date <= end_date:\n",
    "        yield curr_date \n",
    "        curr_date += timedelta(days=days_num)\n",
    "    if curr_date != end_date:\n",
    "        yield end_date\n",
    "\n",
    "def pjm_data_downloading(start_time, end_time, variable_name, info_dict_PJM):\n",
    "    variable_str = info_dict_PJM[variable_name]['variable_str']\n",
    "    variable_date_str = info_dict_PJM[variable_name]['variable_date_str']\n",
    "    PJM_no_hist_variable_list = ['solar_forecast_5min_PJM','solar_forecast_hourly_PJM','wind_forecast_5min_PJM','wind_forecast_hourly_PJM']\n",
    "    \n",
    "    hdr ={\n",
    "            # Request headers\n",
    "            'Cache-Control': 'no-cache',\n",
    "            'Ocp-Apim-Subscription-Key': '336423db3cd243a3841d772330f22cc7',\n",
    "            }\n",
    "    urls = []\n",
    "    df_results = pd.DataFrame()\n",
    "    \n",
    "    ####################################\n",
    "    if variable_name in PJM_no_hist_variable_list:\n",
    "        print(\"Note: PJM does not store renewable forecast data beyond 30 days, the function will turn to download last 30 days' data\")\n",
    "        current_date = datetime.now()# Get the current date\n",
    "        formatted_current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        formatted_30_days_ago_date = (datetime.now()-timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
    "        if (variable_name == 'solar_forecast_5min_PJM' or variable_name == 'wind_forecast_5min_PJM'):\n",
    "        ## 5 min level data beyond the capacity of single PJM API call, turn it to mutiple API call\n",
    "            try:\n",
    "                for iter_days in range(9):\n",
    "                    start_time_iter = (current_date-timedelta(days=iter_days*3+3)).strftime(\"%Y-%m-%d\")\n",
    "                    end_time_iter = (current_date-timedelta(days=iter_days*3)).strftime(\"%Y-%m-%d\")\n",
    "                    url = (\"https://api.pjm.com/api/v1/\" + variable_str +\n",
    "                           \"?rowCount=50000&order=Asc&startRow=1&\" + variable_date_str + \n",
    "                           \"=\" + start_time_iter + \"%2005:00%20to%20\" + end_time_iter + \"%2004:00\")\n",
    "                    urls.append(url)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        else:\n",
    "            try:\n",
    "                start_time_iter = current_date\n",
    "                url = (\"https://api.pjm.com/api/v1/\" + variable_str +\n",
    "                       \"?rowCount=50000&order=Asc&startRow=1&\" + variable_date_str + \n",
    "                       \"=\" + formatted_30_days_ago_date + \"%2005:00%20to%20\" + formatted_current_date + \"%2004:00\")\n",
    "                urls.append(url)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    ####################################       \n",
    "    elif variable_name == 'outage_forecast_daily_PJM':\n",
    "        try:\n",
    "            url = (\"https://api.pjm.com/api/v1/\" + variable_str +\n",
    "                   \"?rowCount=50000&order=Asc&startRow=1&\" + variable_date_str + \n",
    "                   \"=\" + start_time)\n",
    "            \n",
    "            urls.append(url)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "    ####################################\n",
    "    elif variable_name == 'DA_LMP_PJM'or variable_name == 'RT_LMP_PJM':  \n",
    "        try:\n",
    "            start_time_list = start_time.split('-')\n",
    "            end_time_list = end_time.split('-')\n",
    "            d0 = date(int(start_time_list[0]), int(start_time_list[1]), int(start_time_list[2]))\n",
    "            d1 = date(int(end_time_list[0]), int(end_time_list[1]), int(end_time_list[2]))\n",
    "            \n",
    "            if variable_name == 'DA_LMP_PJM':#increase download threadhold\n",
    "                days_num = 300\n",
    "            else:\n",
    "                days_num = 150\n",
    "            \n",
    "            date_var_list = date_range_list(d0, d1, days_num= days_num)\n",
    "            urls = []\n",
    "            iter_num = 0\n",
    "            for i_date in date_var_list:\n",
    "                #print(str(i_date),iter_num)\n",
    "                if iter_num == 0:\n",
    "                    start_d = str(i_date)\n",
    "                elif iter_num != 0:\n",
    "                    end_d = str(i_date)\n",
    "                    if variable_name == 'DA_LMP_PJM':\n",
    "                        url = (\"https://api.pjm.com/api/v1/\" + variable_str +\n",
    "                                   \"?rowCount=50000&order=Asc&startRow=1&\" + variable_date_str + \n",
    "                                   \"=\" + start_d + \"%2005:00%20to%20\" + end_d + \"%2004:00\"+\"&pnode_id=1\")\n",
    "                    elif variable_name == 'RT_LMP_PJM':\n",
    "                        url = (\"https://api.pjm.com/api/v1/\" + variable_str +\n",
    "                                   \"?rowCount=50000&order=Asc&startRow=1&\" + variable_date_str + \n",
    "                                   \"=\" + start_d + \"%2005:00%20to%20\" + end_d + \"%2004:55\"+\"&pnode_id=1\")\n",
    "                    urls.append(url)\n",
    "                    start_d = str(i_date)\n",
    "                iter_num = iter_num + 1\n",
    "            #urls.append(url)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    ####################################\n",
    "    else:  \n",
    "        try:\n",
    "            start_time_list = start_time.split('-')\n",
    "            end_time_list = end_time.split('-')\n",
    "            d0 = date(int(start_time_list[0]), int(start_time_list[1]), int(start_time_list[2]))\n",
    "            d1 = date(int(end_time_list[0]), int(end_time_list[1]), int(end_time_list[2]))\n",
    "            if variable_name == 'DA_LMP_PJM':\n",
    "                days_num \n",
    "            date_var_list = date_range_list(d0, d1, days_num=7)\n",
    "            urls = []\n",
    "            iter_num = 0\n",
    "            for i_date in date_var_list:\n",
    "                #print(str(i_date),iter_num)\n",
    "                if iter_num == 0:\n",
    "                    start_d = str(i_date)\n",
    "                elif iter_num != 0:\n",
    "                    end_d = str(i_date)\n",
    "                    url = (\"https://api.pjm.com/api/v1/\" + variable_str +\n",
    "                               \"?rowCount=50000&order=Asc&startRow=1&\" + variable_date_str + \n",
    "                               \"=\" + start_d + \"%2005:00%20to%20\" + end_d + \"%2004:00\")\n",
    "                    print(url)\n",
    "                    urls.append(url)\n",
    "                    start_d = str(i_date)\n",
    "                iter_num = iter_num + 1\n",
    "            \n",
    "            #urls.append(url)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    ####################################\n",
    "    for i_url, url in enumerate(urls):\n",
    "        #time.sleep(random.randint(1, 5))\n",
    "        req = urllib.request.Request(url, headers=hdr)\n",
    "        req.get_method = lambda: 'GET'\n",
    "        response = urllib.request.urlopen(req)\n",
    "        print(response.getcode())\n",
    "        results = response.read()\n",
    "        json_data = json.loads(results.decode('utf-8'))\n",
    "        print(url)\n",
    "        df_results_1 = pd.DataFrame(json_data['items'])\n",
    "        print(df_results_1)\n",
    "        if i_url % 4 == 0 and i_url!=0:#the whole loop used to reset the PJM api call\n",
    "            time.sleep(random.randint(60, 62)) #take a sleep to make it like human bechavior\n",
    "            url_random = \"https://api.pjm.com/api/v1/load_frcstd_hist?rowCount=50000&order=Asc&startRow=1\"\n",
    "            req = urllib.request.Request(url_random, headers=hdr)#take a random api call to reset the count\n",
    "            req.get_method = lambda: 'GET'\n",
    "            response = urllib.request.urlopen(req)\n",
    "            print('Reset the api count')\n",
    "        df_results = pd.concat([df_results,df_results_1], ignore_index=True)\n",
    "    #print(df_results)\n",
    "    \n",
    "    return df_results\n",
    "df_results = pjm_data_downloading(start_time, end_time, variable_name, info_dict_PJM)\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd296f35-9549-40c7-83d1-94ac280f1214",
   "metadata": {},
   "source": [
    "# National Weather Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd420550-19e8-46ec-b31f-9618fb6fa8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import http.client\n",
    "from urllib.parse import urlparse\n",
    "variable_name = input('Enter the Variable Name (string): ')\n",
    "if len(variable_name) < 1:\n",
    "    variable_name = 'Temp'\n",
    "\n",
    "year_str = input('Enter the year (string): ')\n",
    "if len(year_str) < 1:\n",
    "    year_str = '2024'\n",
    "\n",
    "info_dict_NWS = {'Temp':{'variable_str':'temp','file_str': \"YEUZ98_KWBN_\"},\n",
    "    'DewPoint':{'variable_str':'td','file_str': \"YFUZ98_KWBN_\"},\n",
    "    'WindDirection':{'variable_str':'wdir','file_str': \"YBUZ98_KWBN_\"},\n",
    "    'WindSpeed':{'variable_str':'wspd','file_str': \"YCUZ98_KWBN_\"},\n",
    "    'SkyCover':{'variable_str':'sky','file_str': \"YAUZ98_KWBN_\"},\n",
    "    'RelativeHumidity':{'variable_str':'rhm','file_str': \"YRUZ98_KWBN_\"},\n",
    "    'ApparentTemp':{'variable_str':'apt','file_str': \"YTUZ98_KWBN_\"},\n",
    "    }\n",
    "\n",
    "#variable_str = info_dict_NWS[variable_name]['variable_str']\n",
    "#path_str = \"https://noaa-ndfd-pds.s3.amazonaws.com/wmo/\"+ variable_str + \"/\"\n",
    "#file_str = info_dict_NWS[variable_name]['file_str']\n",
    "\n",
    "def check_link_exists(url):\n",
    "    try:\n",
    "        parsed_url = urlparse(url)\n",
    "        conn = http.client.HTTPSConnection(parsed_url.netloc)\n",
    "        conn.request(\"HEAD\", parsed_url.path)\n",
    "        response = conn.getresponse()\n",
    "        return response.status == 200\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return False\n",
    "\n",
    "def check_file_name_previous(path_str, file_str,time_str, year_str, month_str, day_str, hour_int):#Used if the current hour's file is not exist\n",
    "    file_hour_index = 0\n",
    "    mins = 0\n",
    "    result = False\n",
    "    hour_delta = 1\n",
    "    url_index = (path_str + time_str + file_str + year_str \n",
    "                     + month_str + day_str + str(hour_int-hour_delta))\n",
    "    while result != True:\n",
    "        if mins>= 60:\n",
    "            mins = 0\n",
    "            hour_delta = hour_delta + 1\n",
    "            hour_idx = hour_int-hour_delta\n",
    "            url_index = (path_str + time_str + file_str + year_str\n",
    "                     + month_str + day_str + str(hour_idx))\n",
    "            #print(\"error\")\n",
    "            #break\n",
    "        if mins < 10:\n",
    "            mins_str = \"0\"+ str(mins)\n",
    "        else:\n",
    "            mins_str = str(mins)\n",
    "        url = url_index + mins_str\n",
    "        result = check_link_exists(url)\n",
    "        mins = mins + 1\n",
    "    file_exist_url = url_index + mins_str#str(mins-1)\n",
    "    return file_exist_url, hour_delta\n",
    "\n",
    "def check_file_name(path_str, file_str, time_str, year_str, month_str, day_str, hour_int):\n",
    "    file_hour_index = 0\n",
    "    mins = 0\n",
    "    result = False\n",
    "    url_index = (path_str + time_str + file_str + year_str \n",
    "                     + month_str + day_str + str(hour_int))\n",
    "    \n",
    "    while result != True:\n",
    "        if mins>= 60:\n",
    "            print(\"error:current hour's weather not availible\")\n",
    "            url_previous, file_hour_index = check_file_name_previous(path_str, file_str, time_str, year_str, month_str, day_str, hour_int)\n",
    "            #url_previous \n",
    "            file_exist_url = url_previous #url_index + str(mins-1)\n",
    "            return file_exist_url, file_hour_index\n",
    "            break\n",
    "        if mins < 10:\n",
    "            mins_str = \"0\"+ str(mins)\n",
    "        else:\n",
    "            mins_str = str(mins)\n",
    "        url = url_index + mins_str\n",
    "        result = check_link_exists(url)\n",
    "        mins = mins + 1\n",
    "    file_exist_url = url_index + mins_str#str(mins-1)\n",
    "    return file_exist_url, file_hour_index\n",
    "#print(check_file_name(url_index))\n",
    "\n",
    "\n",
    "def download_links_list_generation(info_dict,variable_name_str,hour_int,year_str):\n",
    "    \n",
    "    '''\n",
    "    info_dict: dict for the variable infomation list for \n",
    "    variable_name_str: which variable are downloading ('Temp','DewPoint','WindDirection','WindSpeed','SkyCover','RelativeHumidity','ApparentTemp')\n",
    "    hour_int: which hour as the reference for the forcast scan\n",
    "    year_str: which year you want downloading\n",
    "    '''\n",
    "    variable_str = info_dict[variable_name_str]['variable_str']\n",
    "    path_str = \"https://noaa-ndfd-pds.s3.amazonaws.com/wmo/\"+ variable_str + \"/\"\n",
    "    file_str = info_dict[variable_name_str]['file_str']\n",
    "    url_list = []\n",
    "    days_num_month = np.array([31,28,31,30,31,30,31,31,30,31,30,31])\n",
    "    \n",
    "    for i_month in range(12):\n",
    "        for i_day in range(days_num_month[i_month]):\n",
    "            if i_month <9:\n",
    "                month_str = '0'+str(i_month+1)\n",
    "            else:\n",
    "                month_str = str(i_month+1)\n",
    "            if i_day <9:\n",
    "                day_str = '0'+str(i_day+1)\n",
    "            else:\n",
    "                day_str = str(i_day+1)\n",
    "            time_str = year_str+'/'+ month_str +'/'+day_str+'/'\n",
    "            #url_index = (\"https://noaa-ndfd-pds.s3.amazonaws.com/wmo/temp/\" + time_str + \"YEUZ98_KWBN_\"+ year_str \n",
    "            #             + month_str + day_str + \"20\")\n",
    "            result, file_hour_index = check_file_name(path_str, file_str,time_str, year_str, month_str, day_str, hour_int)#url_index\n",
    "            print(result,file_hour_index)\n",
    "            url_list.append(result)\n",
    "            #print(check_file_name(url_index))\n",
    "    return url_list\n",
    "\n",
    "hour_int = 20\n",
    "url_list = download_links_list_generation(info_dict_NWS,variable_name,hour_int,year_str)\n",
    "print(url_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
