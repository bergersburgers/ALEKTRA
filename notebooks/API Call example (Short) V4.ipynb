{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb8344e0-0b22-495a-bba2-402284e4e8b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# MISO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9062964d-4e9e-442b-bf01-bc7376326e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, json\n",
    "import pandas as pd\n",
    "from datetime import datetime, date, timedelta\n",
    "import time\n",
    "import sys, os\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import wget\n",
    "import urllib\n",
    "import warnings\n",
    "import requests\n",
    "\n",
    "\n",
    "start_time = input('Enter the start time(YYYY-MM-DD): ')\n",
    "if len(start_time) < 1:\n",
    "    start_time = '2025-01-01'\n",
    "\n",
    "end_time = input('Enter the end time(YYYY-MM-DD): ')\n",
    "if len(end_time) < 1:\n",
    "    end_time = '2025-01-02'\n",
    "\n",
    "variable_name = input('Enter the Variable name: ')\n",
    "if len(variable_name) < 1:\n",
    "    variable_name = 'demand_forecast_hourly_regional_MISO'\n",
    "\n",
    "info_dict_MISO = {\n",
    "    'solar_forecast_hourly_MISO':{'variable_str':'_mom.xlsx','variable_date_str':'SOLAR HOURLY', \"Unique_variable_name_ISO\": \" \"},\n",
    "    'wind_forecast_hourly_MISO':{'variable_str':'_mom.xlsx','variable_date_str':'WIND HOURLY'},\n",
    "    'outage_forecast_daily_MISO':{'variable_str':'_mom.xlsx','variable_date_str':'OUTAGE'},\n",
    "    'demand_forecast_hourly_zone_MISO':{'variable_str':'df_al.xls','variable_date_str':'n/a'},\n",
    "    'demand_forecast_hourly_regional_MISO':{'variable_str':'rf_al.xls','variable_date_str':'n/a'},\n",
    "    'DA_LMP_MISO':{'variable_str':'da_exante_lmp.csv','variable_date_str':'n/a'},# Miso will change it to New API\n",
    "    'RT_LMP_MISO':{'variable_str':'5min_exante_lmp.xlsx','variable_date_str':'n/a'},# Miso will change it to New API\n",
    "    'DA_HUB_price_MISO': {'variable_str': 'da_pr.xls','variable_date_str':'n/a'},\n",
    "    'RT_HUB_price_MISO': {'variable_str': 'rt_pr.xls','variable_date_str':'n/a'},\n",
    "    }\n",
    "\n",
    "def date_range_list(start_date, end_date, days_num=1):\n",
    "    # Return generator for a list datetime.date objects (inclusive) between start_date and end_date (inclusive).\n",
    "    curr_date = start_date\n",
    "    while curr_date <= end_date:\n",
    "        yield curr_date \n",
    "        curr_date += timedelta(days=days_num)\n",
    "\n",
    "\n",
    "def miso_data_downloading(start_time, end_time, variable_name, info_dict_MISO):\n",
    "    start_time_list = start_time.split('-')\n",
    "    end_time_list = end_time.split('-')\n",
    "\n",
    "    d0 = date(int(start_time_list[0]), int(start_time_list[1]), int(start_time_list[2]))\n",
    "    d1 = date(int(end_time_list[0]), int(end_time_list[1]), int(end_time_list[2]))\n",
    "    data_array = []\n",
    "    date_list = date_range_list(d0, d1)\n",
    "\n",
    "    variable_str = info_dict_MISO[variable_name]['variable_str']\n",
    "    variable_date_str = info_dict_MISO[variable_name]['variable_date_str']\n",
    "    \n",
    "    ###\n",
    "    # variable_name=='DA_HUB_price_MISO' or variable_name=='RT_LMP_MISO'\n",
    "    ###\n",
    "    if variable_name=='DA_HUB_price_MISO' or variable_name=='RT_LMP_MISO':\n",
    "        for day in date_list:\n",
    "            date_list = str(day).split('-')\n",
    "            YYYYMMDD = date_list[0]+date_list[1]+date_list[2]\n",
    "            url = 'https://docs.misoenergy.org/marketreports/'+ YYYYMMDD +'_' + variable_str\n",
    "\n",
    "            df_0 = pd.read_excel(url, index_col=None,na_values=['NA'], usecols=\"B\")\n",
    "            #print(df_0)\n",
    "            header_num = 0\n",
    "            header = 0\n",
    "            Header_str = 'NaN'\n",
    "            while Header_str != 'MISO System':\n",
    "                Header_str = str(df_0.iloc[header,0])\n",
    "                header = header_num\n",
    "                header_num = header_num + 1\n",
    "                if header > len(df_0['Unnamed: 1']):\n",
    "                    break\n",
    "            #print(header)\n",
    "            df = pd.read_excel(io = url,index_col= None , na_values=['NA'], header=header, nrows = 24)#, usecols=[\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\"]\n",
    "            print(df)\n",
    "            if str(day) == str(start_time):\n",
    "                sum_df = df\n",
    "            else:\n",
    "                sum_df = pd.concat([sum_df, df], ignore_index = True)\n",
    "\n",
    "    \n",
    "    \n",
    "    ###\n",
    "    # elif (variable_name == 'solar_forecast_hourly_MISO' or variable_name == 'wind_forecast_hourly_MISO' or variable_name == 'outage_forecast_daily_MISO')\n",
    "    ###\n",
    "    elif (variable_name == 'solar_forecast_hourly_MISO' or variable_name == 'wind_forecast_hourly_MISO' \n",
    "          or variable_name == 'outage_forecast_daily_MISO'):\n",
    "        i = 0\n",
    "        for day in date_list:\n",
    "            date_str = str(day).split('-')\n",
    "            YYYYMMDD = date_str[0]+date_str[1]+date_str[2]\n",
    "            current_date = day + timedelta(days = 1)\n",
    "            current_date_str = str(current_date).split('-')\n",
    "            \n",
    "            url_2 = 'https://docs.misoenergy.org/marketreports/'+ YYYYMMDD + '_'+variable_str\n",
    "            print(YYYYMMDD)\n",
    "            header = 0\n",
    "            try:\n",
    "                df = pd.read_excel(url_2, index_col=None, sheet_name=variable_date_str,na_values=['NA'], usecols=\"A\")\n",
    "                header_num = 0\n",
    "                header = 0\n",
    "                Header_str = 'NaN'\n",
    "                while Header_str != 'DAY HE' and Header_str != 'Day HE':#or Header_str != 'Day HE'\n",
    "                    Header_str = str(df.iloc[header,0])\n",
    "                    header = header_num\n",
    "                    header_num = header_num + 1\n",
    "                    if header > len(df['Unnamed: 0']):\n",
    "                        break\n",
    "                df_mom = pd.read_excel(io = url_2,index_col= None , na_values=['NA'], header=header, usecols='A,B,C,D',#,D\n",
    "                                     sheet_name=variable_date_str,nrows = 48,engine=\"openpyxl\")\n",
    "                time_info = 'NaN'\n",
    "                time_info_1am = current_date_str[1] + '/'+ current_date_str[2] + '/' + current_date_str[0] + ' 1'\n",
    "                time_info_7am = current_date_str[1] + '/'+ current_date_str[2] + '/' + current_date_str[0] + ' 7'\n",
    "                \n",
    "                time_idx = 0\n",
    "                while time_info != time_info_1am:\n",
    "                    time_info = str(''.join(list(df_mom.iloc[time_idx,0])[2:15]))\n",
    "                    time_idx = time_idx + 1\n",
    "                    #if time_info = \n",
    "                    if time_idx > len(df_mom.iloc[:,0]):\n",
    "                        break\n",
    "                iloc_start = time_idx - 1\n",
    "                iloc_end = iloc_start+24\n",
    "                \n",
    "                \n",
    "                df_mom = df_mom.iloc[iloc_start:iloc_end,:]\n",
    "                data_array.append(1)\n",
    "            except:\n",
    "                try:\n",
    "                    df = pd.read_excel(url_1, index_col=None, sheet_name=variable_date_str,na_values=['NA'], usecols=\"A\")\n",
    "                    header_num = 0\n",
    "                    header = 0\n",
    "                    Header_str = 'NaN'\n",
    "                    while Header_str != 'DAY HE'and Header_str != 'Day HE':#or Header_str != 'Day HE'\n",
    "                        Header_str = str(df.iloc[header,0])\n",
    "                        header = header_num\n",
    "                        header_num = header_num + 1\n",
    "                        if header > len(df['Unnamed: 0']):\n",
    "                            break\n",
    "        \n",
    "                    df_mom = pd.read_excel(io = url_1,index_col= None , na_values=['NA'], header=header, usecols='A,B,C,D',#,D\n",
    "                                     sheet_name=variable_date_str,nrows = 168,engine=\"openpyxl\")\n",
    "                    time_info = 'NaN'\n",
    "                    time_info_1am = current_date_str[1] + '/'+ current_date_str[2] + '/' + current_date_str[0] + ' 1'\n",
    "                    time_info_7am = current_date_str[1] + '/'+ current_date_str[2] + '/' + current_date_str[0] + ' 7'\n",
    "        \n",
    "                    time_idx = 0\n",
    "                    while time_info != time_info_1am:\n",
    "                        time_info = str(''.join(list(df_mom.iloc[time_idx,0])[2:15]))\n",
    "                        time_idx = time_idx + 1\n",
    "                        if time_idx > len(df_mom.iloc[:,0]):\n",
    "                            break\n",
    "                    iloc_start = time_idx - 1\n",
    "                    iloc_end = iloc_start+24\n",
    "        \n",
    "                    df_mom = df_mom.iloc[iloc_start:iloc_end,:]\n",
    "                    data_array.append(2)\n",
    "            \n",
    "                except:\n",
    "                    intial_date = date(int(date_str[0]), int(date_str[1]), int(date_str[2]))\n",
    "                    day_i = 0\n",
    "                    #day_i = day_i + 1\n",
    "                    file_date = intial_date + timedelta(days = -day_i)\n",
    "                    file_date_str = str(file_date).split('-')\n",
    "                    YYYYMMDD_1 = file_date_str[0]+file_date_str[1]+file_date_str[2]\n",
    "                    url_try = 'https://docs.misoenergy.org/marketreports/'+ YYYYMMDD_1 + variable_str\n",
    "        \n",
    "                    response = requests.get(url_try)\n",
    "                    while response.status_code != 200:\n",
    "                        file_date = intial_date + timedelta(days = -day_i)\n",
    "                        file_date_str = str(file_date).split('-')\n",
    "                        YYYYMMDD_1 = file_date_str[0]+file_date_str[1]+file_date_str[2]\n",
    "                        url_try = 'https://docs.misoenergy.org/marketreports/'+ YYYYMMDD_1 + variable_str\n",
    "                        response = requests.get(url_try)\n",
    "                        day_i = day_i + 1\n",
    "                        print(\"Found previous: \", YYYYMMDD_1)\n",
    "                    #url_1_1 = 'https://docs.misoenergy.org/marketreports/'+ YYYYMMDD + '_mom.xlsx'\n",
    "                    df = pd.read_excel(url_try, index_col=None, sheet_name='WIND HOURLY',na_values=['NA'], usecols=\"A\")\n",
    "                    header_num = 0\n",
    "                    header = 0\n",
    "                    Header_str = 'NaN'\n",
    "                    while Header_str != 'DAY HE'and Header_str != 'Day HE':#or Header_str != 'Day HE'\n",
    "                        Header_str = str(df.iloc[header,0])\n",
    "                        header = header_num\n",
    "                        header_num = header_num + 1\n",
    "                        if header > len(df['Unnamed: 0']):\n",
    "                            break\n",
    "        \n",
    "                    df_mom = pd.read_excel(io = url_try,index_col= None , na_values=['NA'], header=header, usecols='A,B,C,D',#,D\n",
    "                                     sheet_name='WIND HOURLY',nrows = 168,engine=\"openpyxl\")\n",
    "                    time_info = 'NaN'\n",
    "                    time_info_1am = current_date_str[1] + '/'+ current_date_str[2] + '/' + current_date_str[0] + ' 1'\n",
    "                    time_info_7am = current_date_str[1] + '/'+ current_date_str[2] + '/' + current_date_str[0] + ' 7'\n",
    "        \n",
    "                    time_idx = 0\n",
    "                    while time_info != time_info_1am:\n",
    "                        time_info = str(''.join(list(df_mom.iloc[time_idx,0])[2:15]))\n",
    "                        time_idx = time_idx + 1\n",
    "                        if time_idx > len(df_mom.iloc[:,0]):\n",
    "                            break\n",
    "                    iloc_start = time_idx - 1\n",
    "                    iloc_end = iloc_start+24\n",
    "        \n",
    "                    df_mom = df_mom.iloc[iloc_start:iloc_end,:]\n",
    "                    data_array.append(2)\n",
    "                if Header_str == 'Day HE':\n",
    "                    df_mom = df_mom.rename(columns={'Day HE': 'DAY HE', 'North': 'North','Central': 'Central'})\n",
    "            \n",
    "            if str(day) == str(start_time):\n",
    "                sum_df = df_mom\n",
    "            else:\n",
    "                sum_df = pd.concat([sum_df, df_mom], ignore_index = False)#, ignore_index = True\n",
    "            url_1 = url_2\n",
    "            i = i + 1\n",
    "    ###\n",
    "    # elif (variable_name == 'outage_forecast_daily_MISO')\n",
    "    ###\n",
    "    elif (variable_name == 'outage_forecast_daily_MISO'):\n",
    "        i = 0\n",
    "        for day in date_list:\n",
    "            date_str = str(day).split('-')\n",
    "            YYYYMMDD = date_str[0]+date_str[1]+date_str[2]\n",
    "            current_date = day + timedelta(days = 1)\n",
    "            current_date_str = str(current_date).split('-')\n",
    "            \n",
    "            url_2 = 'https://docs.misoenergy.org/marketreports/'+ YYYYMMDD + '_' + variable_str\n",
    "            print(YYYYMMDD)\n",
    "            header = 0\n",
    "            try:\n",
    "                #df = pd.read_excel(url_2, index_col=None, sheet_name='OUTAGE',na_values=['NA'], usecols=\"C\")\n",
    "                #header_num = 0\n",
    "                header = 6\n",
    "                index_day = 2\n",
    "                df_outage = pd.read_excel(io = url_2,index_col= None , na_values=['NA'], header=header, usecols='A,B,C',#,D\n",
    "                                     sheet_name=variable_date_str,nrows = 16,engine=\"openpyxl\")\n",
    "                \n",
    "                sum_north = df_outage[df_outage[\"Unnamed: 0\"]==\"North\"].sum()\n",
    "                sum_central = df_outage[df_outage[\"Unnamed: 0\"]==\"Central\"].sum()\n",
    "                sum_south = df_outage[df_outage[\"Unnamed: 0\"]==\"South\"].sum()\n",
    "                sum_miso = df_outage[df_outage[\"Unnamed: 0\"]==\"MISO\"].sum()\n",
    "                df_sum_data_day =  pd.DataFrame({'Outage_North': [sum_north.iloc[index_day]],'Outage_Central': [sum_central.iloc[index_day]],\n",
    "                               'Outage_South': [sum_south.iloc[index_day]],'Outage_MISO': [sum_miso.iloc[index_day]]})\n",
    "                df_outage_sum = pd.DataFrame()\n",
    "                for i_hour in range(24):\n",
    "                    df_outage_sum = pd.concat([df_sum_data_day, df_outage_sum], ignore_index = False)\n",
    "                \n",
    "                data_array.append(1)\n",
    "            except:\n",
    "                try:\n",
    "                    #df = pd.read_excel(url_1, index_col=None, sheet_name='SOLAR HOURLY',na_values=['NA'], usecols=\"A,B,C,D\")\n",
    "                    header_num = 0\n",
    "                    header = 6\n",
    "                    \n",
    "                    df_outage = pd.read_excel(io = url_1,index_col= None , na_values=['NA'], header=header, usecols='A,B,C,D',#,D\n",
    "                                     sheet_name=variable_date_str,nrows = 16,engine=\"openpyxl\")\n",
    "                    index_day = 3\n",
    "                    sum_north = df_outage[df_outage[\"Unnamed: 0\"]==\"North\"].sum()\n",
    "                    sum_central = df_outage[df_outage[\"Unnamed: 0\"]==\"Central\"].sum()\n",
    "                    sum_south = df_outage[df_outage[\"Unnamed: 0\"]==\"South\"].sum()\n",
    "                    sum_miso = df_outage[df_outage[\"Unnamed: 0\"]==\"MISO\"].sum()\n",
    "                    df_sum_data_day =  pd.DataFrame({'Outage_North': [sum_north.iloc[index_day]],'Outage_Central': [sum_central.iloc[index_day]],\n",
    "                               'Outage_South': [sum_south.iloc[index_day]],'Outage_MISO': [sum_miso.iloc[index_day]]})\n",
    "                    df_outage_sum = pd.DataFrame()\n",
    "                    for i_hour in range(24):\n",
    "                        df_outage_sum = pd.concat([df_sum_data_day, df_outage_sum], ignore_index = False)\n",
    "                    data_array.append(2)\n",
    "            \n",
    "                except:\n",
    "                    print(\"Can not find: \", YYYYMMDD)\n",
    "                    intial_date = date(int(date_str[0]), int(date_str[1]), int(date_str[2]))\n",
    "                    day_i = 0\n",
    "                    #day_i = day_i + 1\n",
    "                    file_date = intial_date + timedelta(days = -day_i)\n",
    "                    file_date_str = str(file_date).split('-')\n",
    "                    YYYYMMDD_1 = file_date_str[0]+file_date_str[1]+file_date_str[2]\n",
    "                    url_try = 'https://docs.misoenergy.org/marketreports/'+ YYYYMMDD_1+ '_'+variable_str\n",
    "        \n",
    "                    response = requests.get(url_try)\n",
    "                    while response.status_code != 200:\n",
    "                        file_date = intial_date + timedelta(days = -day_i)\n",
    "                        file_date_str = str(file_date).split('-')\n",
    "                        YYYYMMDD_1 = file_date_str[0]+file_date_str[1]+file_date_str[2]\n",
    "                        url_try = 'https://docs.misoenergy.org/marketreports/'+ YYYYMMDD_1 + '_' + variable_str\n",
    "                        response = requests.get(url_try)\n",
    "                        day_i = day_i + 1\n",
    "                    #print(\"Found previous: \", YYYYMMDD_1)\n",
    "                    #url_1_1 = 'https://docs.misoenergy.org/marketreports/'+ YYYYMMDD + '_mom.xlsx'\n",
    "                    #df = pd.read_excel(url_try, index_col=None, sheet_name='OUTAGE',na_values=['NA'], usecols=\"A,B,C,D,E,F,G,H,I\")\n",
    "                    header = 6\n",
    "                    \n",
    "                    df_outage = pd.read_excel(io = url_try,index_col= None , na_values=['NA'], header=header, usecols=\"A,B,C,D,E,F,G,H,I\",#,D\n",
    "                                     sheet_name=variable_date_str,nrows = 16,engine=\"openpyxl\")\n",
    "                    index_day = day_i+1\n",
    "                    print(\"!!!!!\",index_day)\n",
    "                    \n",
    "                    sum_north = df_outage[df_outage[\"Unnamed: 0\"]==\"North\"].sum()\n",
    "                    sum_central = df_outage[df_outage[\"Unnamed: 0\"]==\"Central\"].sum()\n",
    "                    sum_south = df_outage[df_outage[\"Unnamed: 0\"]==\"South\"].sum()\n",
    "                    sum_miso = df_outage[df_outage[\"Unnamed: 0\"]==\"MISO\"].sum()\n",
    "                    df_sum_data_day =  pd.DataFrame({'Outage_North': [sum_north.iloc[index_day]],'Outage_Central': [sum_central.iloc[index_day]],\n",
    "                               'Outage_South': [sum_south.iloc[index_day]],'Outage_MISO': [sum_miso.iloc[index_day]]})\n",
    "                    df_outage_sum = pd.DataFrame()\n",
    "                    for i_hour in range(24):\n",
    "                        df_outage_sum = pd.concat([df_sum_data_day, df_outage_sum], ignore_index = False)\n",
    "                    print(df_outage_sum)\n",
    "                data_array.append(2)\n",
    "                \n",
    "            \n",
    "            if str(day) == str(start_time):\n",
    "                sum_df = df_outage_sum\n",
    "            else:\n",
    "                sum_df = pd.concat([sum_df, df_outage_sum], ignore_index = False)#, ignore_index = True\n",
    "            url_1 = url_2\n",
    "            i = i + 1\n",
    "    ###\n",
    "    # elif (variable_name == 'demand_forecast_hourly_zone_MISO')\n",
    "    ###\n",
    "    elif variable_name == 'demand_forecast_hourly_zone_MISO':\n",
    "        for day in date_list:\n",
    "            date_list = str(day).split('-')\n",
    "            YYYYMMDD = date_list[0]+date_list[1]+date_list[2]\n",
    "            url = 'https://docs.misoenergy.org/marketreports/'+ YYYYMMDD + '_' + variable_str\n",
    "        \n",
    "            df = pd.read_excel(io = url,index_col= None , na_values=['NA'], \n",
    "                               header=None, skiprows = [i for i in (range(32))], nrows = 24).drop([3,5,7,9,11,13,15], axis=1)#, usecols=[\"C\",\"E\",\"G\",\"I\",\"K\",\"M\",\"O\"]\n",
    "            df.rename(columns={0: 'Date', 1: 'Hour', 2: 'Zone1', 4: 'Zone2_7', 6: 'Zone3_5', 8: 'Zone4', 10: 'Zone6', 12: 'Zone8_9', 14: 'MISO'}, inplace=True)#print(day)\n",
    "            #print(df)\n",
    "            if str(day) == str(start_time):\n",
    "                sum_df = df\n",
    "            else:\n",
    "                sum_df = pd.concat([sum_df, df], ignore_index = True)\n",
    "\n",
    "    ###\n",
    "    # elif (variable_name == 'demand_forecast_hourly_zone_MISO')\n",
    "    ###\n",
    "    elif (variable_name == 'demand_forecast_hourly_regional_MISO'):\n",
    "        for day in date_list:\n",
    "            date_list = str(day).split('-')\n",
    "            YYYYMMDD = date_list[0]+date_list[1]+date_list[2]\n",
    "            url = 'https://docs.misoenergy.org/marketreports/'+ YYYYMMDD + '_' + variable_str\n",
    "    \n",
    "            df = pd.read_excel(io = url,index_col= None , na_values=['NA'],# North - D; Central - F; MISO - J\n",
    "                               header=None, skiprows = [i for i in (range(34))], nrows = 24).drop([0, 4,6,8,10], axis=1)\n",
    "            df.rename(columns={1: 'Date', 2: 'Hour', 3: 'North', 5: 'Central', 7: 'South', 9: 'MISO'}, inplace=True)\n",
    "            #print(day)\n",
    "            if str(day) == str(start_time):\n",
    "                sum_df = df\n",
    "            else:\n",
    "                sum_df = pd.concat([sum_df, df], ignore_index = True)\n",
    "        \n",
    "    return sum_df\n",
    "\n",
    "\n",
    "sum_df = miso_data_downloading(start_time, end_time, variable_name, info_dict_MISO)\n",
    "print(sum_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f473ed01-f8a7-484c-8db7-a1349fac3153",
   "metadata": {},
   "source": [
    "# PJM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4315a8-283e-4e4b-9903-a84356abde08",
   "metadata": {},
   "source": [
    "## 1. Downloading Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59349543-5957-4087-8105-fb34d180a58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the start time(YYYY-MM-DD):  \n",
      "Enter the end time(YYYY-MM-DD):  \n",
      "Enter the Variable name:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.pjm.com/api/v1/frcstd_gen_outages?rowCount=50000&order=Asc&startRow=1&forecast_date=2024-01-01%2000:00%20to%202024-10-27%2023:00\n",
      "https://api.pjm.com/api/v1/frcstd_gen_outages?rowCount=50000&order=Asc&startRow=1&forecast_date=2024-10-27%2000:00%20to%202025-08-23%2023:00\n",
      "https://api.pjm.com/api/v1/frcstd_gen_outages?rowCount=50000&order=Asc&startRow=1&forecast_date=2025-08-23%2000:00%20to%202025-10-01%2023:00\n",
      "200\n",
      "https://api.pjm.com/api/v1/frcstd_gen_outages?rowCount=50000&order=Asc&startRow=1&forecast_date=2024-01-01%2000:00%20to%202024-10-27%2023:00\n",
      "      forecast_execution_date_ept        forecast_date  \\\n",
      "0             2023-10-02T00:00:00  2024-01-01T00:00:00   \n",
      "1             2023-10-03T00:00:00  2024-01-01T00:00:00   \n",
      "2             2023-10-03T00:00:00  2024-01-02T00:00:00   \n",
      "3             2023-10-04T00:00:00  2024-01-01T00:00:00   \n",
      "4             2023-10-04T00:00:00  2024-01-02T00:00:00   \n",
      "...                           ...                  ...   \n",
      "27204         2024-10-24T00:00:00  2024-10-26T00:00:00   \n",
      "27205         2024-10-24T00:00:00  2024-10-27T00:00:00   \n",
      "27206         2024-10-25T00:00:00  2024-10-26T00:00:00   \n",
      "27207         2024-10-25T00:00:00  2024-10-27T00:00:00   \n",
      "27208         2024-10-26T00:00:00  2024-10-27T00:00:00   \n",
      "\n",
      "       forecast_gen_outage_mw_rto  forecast_gen_outage_mw_west  \\\n",
      "0                             693                          118   \n",
      "1                             693                          118   \n",
      "2                             735                          115   \n",
      "3                             693                          118   \n",
      "4                             735                          115   \n",
      "...                           ...                          ...   \n",
      "27204                       51334                        26230   \n",
      "27205                       52000                        26896   \n",
      "27206                       51328                        26349   \n",
      "27207                       51994                        27015   \n",
      "27208                       49798                        24864   \n",
      "\n",
      "       forecast_gen_outage_mw_other  \n",
      "0                               575  \n",
      "1                               575  \n",
      "2                               620  \n",
      "3                               575  \n",
      "4                               620  \n",
      "...                             ...  \n",
      "27204                         25104  \n",
      "27205                         25104  \n",
      "27206                         24979  \n",
      "27207                         24979  \n",
      "27208                         24934  \n",
      "\n",
      "[27209 rows x 5 columns]\n",
      "200\n",
      "https://api.pjm.com/api/v1/frcstd_gen_outages?rowCount=50000&order=Asc&startRow=1&forecast_date=2024-10-27%2000:00%20to%202025-08-23%2023:00\n",
      "      forecast_execution_date_ept        forecast_date  \\\n",
      "0             2024-07-28T00:00:00  2024-10-27T00:00:00   \n",
      "1             2024-07-29T00:00:00  2024-10-27T00:00:00   \n",
      "2             2024-07-29T00:00:00  2024-10-28T00:00:00   \n",
      "3             2024-07-30T00:00:00  2024-10-27T00:00:00   \n",
      "4             2024-07-30T00:00:00  2024-10-28T00:00:00   \n",
      "...                           ...                  ...   \n",
      "27386         2025-08-20T00:00:00  2025-08-22T00:00:00   \n",
      "27387         2025-08-20T00:00:00  2025-08-23T00:00:00   \n",
      "27388         2025-08-21T00:00:00  2025-08-22T00:00:00   \n",
      "27389         2025-08-21T00:00:00  2025-08-23T00:00:00   \n",
      "27390         2025-08-22T00:00:00  2025-08-23T00:00:00   \n",
      "\n",
      "       forecast_gen_outage_mw_rto  forecast_gen_outage_mw_west  \\\n",
      "0                           49974                        25035   \n",
      "1                           49974                        25035   \n",
      "2                           48778                        23849   \n",
      "3                           49974                        25035   \n",
      "4                           48778                        23849   \n",
      "...                           ...                          ...   \n",
      "27386                           0                            0   \n",
      "27387                           0                            0   \n",
      "27388                           0                            0   \n",
      "27389                           0                            0   \n",
      "27390                           0                            0   \n",
      "\n",
      "       forecast_gen_outage_mw_other  \n",
      "0                             24939  \n",
      "1                             24939  \n",
      "2                             24929  \n",
      "3                             24939  \n",
      "4                             24929  \n",
      "...                             ...  \n",
      "27386                             0  \n",
      "27387                             0  \n",
      "27388                             0  \n",
      "27389                             0  \n",
      "27390                             0  \n",
      "\n",
      "[27391 rows x 5 columns]\n",
      "200\n",
      "https://api.pjm.com/api/v1/frcstd_gen_outages?rowCount=50000&order=Asc&startRow=1&forecast_date=2025-08-23%2000:00%20to%202025-10-01%2023:00\n",
      "     forecast_execution_date_ept        forecast_date  \\\n",
      "0            2025-05-24T00:00:00  2025-08-23T00:00:00   \n",
      "1            2025-05-25T00:00:00  2025-08-23T00:00:00   \n",
      "2            2025-05-25T00:00:00  2025-08-24T00:00:00   \n",
      "3            2025-05-26T00:00:00  2025-08-23T00:00:00   \n",
      "4            2025-05-26T00:00:00  2025-08-24T00:00:00   \n",
      "...                          ...                  ...   \n",
      "3635         2025-09-28T00:00:00  2025-09-30T00:00:00   \n",
      "3636         2025-09-28T00:00:00  2025-10-01T00:00:00   \n",
      "3637         2025-09-29T00:00:00  2025-09-30T00:00:00   \n",
      "3638         2025-09-29T00:00:00  2025-10-01T00:00:00   \n",
      "3639         2025-09-30T00:00:00  2025-10-01T00:00:00   \n",
      "\n",
      "      forecast_gen_outage_mw_rto  forecast_gen_outage_mw_west  \\\n",
      "0                              0                            0   \n",
      "1                              0                            0   \n",
      "2                              0                            0   \n",
      "3                              0                            0   \n",
      "4                              0                            0   \n",
      "...                          ...                          ...   \n",
      "3635                       29106                        14147   \n",
      "3636                       33970                        15614   \n",
      "3637                       29106                        14147   \n",
      "3638                       33970                        15614   \n",
      "3639                       34124                        15614   \n",
      "\n",
      "      forecast_gen_outage_mw_other  \n",
      "0                                0  \n",
      "1                                0  \n",
      "2                                0  \n",
      "3                                0  \n",
      "4                                0  \n",
      "...                            ...  \n",
      "3635                         14959  \n",
      "3636                         18356  \n",
      "3637                         14959  \n",
      "3638                         18356  \n",
      "3639                         18510  \n",
      "\n",
      "[3640 rows x 5 columns]\n",
      "      forecast_execution_date_ept        forecast_date  \\\n",
      "0             2023-10-02T00:00:00  2024-01-01T00:00:00   \n",
      "1             2023-10-03T00:00:00  2024-01-01T00:00:00   \n",
      "2             2023-10-03T00:00:00  2024-01-02T00:00:00   \n",
      "3             2023-10-04T00:00:00  2024-01-01T00:00:00   \n",
      "4             2023-10-04T00:00:00  2024-01-02T00:00:00   \n",
      "...                           ...                  ...   \n",
      "58235         2025-09-28T00:00:00  2025-09-30T00:00:00   \n",
      "58236         2025-09-28T00:00:00  2025-10-01T00:00:00   \n",
      "58237         2025-09-29T00:00:00  2025-09-30T00:00:00   \n",
      "58238         2025-09-29T00:00:00  2025-10-01T00:00:00   \n",
      "58239         2025-09-30T00:00:00  2025-10-01T00:00:00   \n",
      "\n",
      "       forecast_gen_outage_mw_rto  forecast_gen_outage_mw_west  \\\n",
      "0                             693                          118   \n",
      "1                             693                          118   \n",
      "2                             735                          115   \n",
      "3                             693                          118   \n",
      "4                             735                          115   \n",
      "...                           ...                          ...   \n",
      "58235                       29106                        14147   \n",
      "58236                       33970                        15614   \n",
      "58237                       29106                        14147   \n",
      "58238                       33970                        15614   \n",
      "58239                       34124                        15614   \n",
      "\n",
      "       forecast_gen_outage_mw_other  \n",
      "0                               575  \n",
      "1                               575  \n",
      "2                               620  \n",
      "3                               575  \n",
      "4                               620  \n",
      "...                             ...  \n",
      "58235                         14959  \n",
      "58236                         18356  \n",
      "58237                         14959  \n",
      "58238                         18356  \n",
      "58239                         18510  \n",
      "\n",
      "[58240 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta,date\n",
    "import time\n",
    "import random\n",
    "\n",
    "start_time = input('Enter the start time(YYYY-MM-DD): ')\n",
    "if len(start_time) < 1:\n",
    "    start_time = '2024-01-01'\n",
    "\n",
    "end_time = input('Enter the end time(YYYY-MM-DD): ')\n",
    "if len(end_time) < 1:\n",
    "    end_time = '2025-10-01'\n",
    "\n",
    "variable_name = input('Enter the Variable name: ')\n",
    "if len(variable_name) < 1:\n",
    "    variable_name = 'outage_forecast_daily_PJM'\n",
    "\n",
    "info_dict_PJM = {'solar_forecast_5min_PJM':{'variable_str':'five_min_solar_power_forecast','variable_date_str':'datetime_beginning_utc'},\n",
    "    'solar_forecast_hourly_PJM':{'variable_str':'hourly_solar_power_forecast','variable_date_str':'datetime_beginning_utc'},\n",
    "    'wind_forecast_5min_PJM':{'variable_str':'five_min_wind_power_forecast','variable_date_str':'datetime_beginning_utc'},\n",
    "    'wind_forecast_hourly_PJM':{'variable_str':'hourly_wind_power_forecast','variable_date_str':'datetime_beginning_utc'},\n",
    "    'outage_forecast_daily_PJM':{'variable_str':'frcstd_gen_outages','variable_date_str':'forecast_date'},\n",
    "    'demand_forecast_hourly_PJM':{'variable_str':'load_frcstd_hist','variable_date_str':'forecast_hour_beginning_utc'},\n",
    "    'DA_LMP_PJM':{'variable_str':'da_hrl_lmps','variable_date_str':'datetime_beginning_utc'},\n",
    "    'RT_LMP_PJM':{'variable_str':'rt_fivemin_mnt_lmps','variable_date_str':'datetime_beginning_utc'},\n",
    "    'demand_real_hourly_PJM':{'variable_str':'frcstd_gen_outages','variable_date_str':'forecast_date'},\n",
    "    }\n",
    "def date_range_list(start_date, end_date, days_num=1):\n",
    "    # Return generator for a list datetime.date objects (inclusive) between start_date and end_date (inclusive).\n",
    "    curr_date = start_date\n",
    "    while curr_date <= end_date:\n",
    "        yield curr_date \n",
    "        curr_date += timedelta(days=days_num)\n",
    "    if curr_date != end_date:\n",
    "        yield end_date\n",
    "\n",
    "def pjm_data_downloading(start_time, end_time, variable_name, info_dict_PJM):\n",
    "    variable_str = info_dict_PJM[variable_name]['variable_str']\n",
    "    variable_date_str = info_dict_PJM[variable_name]['variable_date_str']\n",
    "    PJM_no_hist_variable_list = ['solar_forecast_5min_PJM','solar_forecast_hourly_PJM','wind_forecast_5min_PJM','wind_forecast_hourly_PJM']\n",
    "    \n",
    "    hdr ={\n",
    "            # Request headers\n",
    "            'Cache-Control': 'no-cache',\n",
    "            'Ocp-Apim-Subscription-Key': '336423db3cd243a3841d772330f22cc7',\n",
    "            }\n",
    "    urls = []\n",
    "    df_results = pd.DataFrame()\n",
    "    \n",
    "    ####################################\n",
    "    if variable_name in PJM_no_hist_variable_list:\n",
    "        print(\"Note: PJM does not store renewable forecast data beyond 30 days, the function will turn to download last 30 days' data\")\n",
    "        current_date = datetime.now()# Get the current date\n",
    "        formatted_current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        formatted_30_days_ago_date = (datetime.now()-timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
    "        if (variable_name == 'solar_forecast_5min_PJM' or variable_name == 'wind_forecast_5min_PJM'):\n",
    "        ## 5 min level data beyond the capacity of single PJM API call, turn it to mutiple API call\n",
    "            try:\n",
    "                for iter_days in range(9):\n",
    "                    start_time_iter = (current_date-timedelta(days=iter_days*3+3)).strftime(\"%Y-%m-%d\")\n",
    "                    end_time_iter = (current_date-timedelta(days=iter_days*3)).strftime(\"%Y-%m-%d\")\n",
    "                    url = (\"https://api.pjm.com/api/v1/\" + variable_str +\n",
    "                           \"?rowCount=50000&order=Asc&startRow=1&\" + variable_date_str + \n",
    "                           \"=\" + start_time_iter + \"%2005:00%20to%20\" + end_time_iter + \"%2004:00\")\n",
    "                    urls.append(url)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        else:\n",
    "            try:\n",
    "                start_time_iter = current_date\n",
    "                url = (\"https://api.pjm.com/api/v1/\" + variable_str +\n",
    "                       \"?rowCount=50000&order=Asc&startRow=1&\" + variable_date_str + \n",
    "                       \"=\" + formatted_30_days_ago_date + \"%2005:00%20to%20\" + formatted_current_date + \"%2004:00\")\n",
    "                urls.append(url)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    ####################################       \n",
    "    #elif variable_name == 'outage_forecast_daily_PJM':\n",
    "    #    try:\n",
    "    #        url = (\"https://api.pjm.com/api/v1/\" + variable_str +\n",
    "    #               \"?rowCount=50000&order=Asc&startRow=1&\" + variable_date_str + \n",
    "    #               \"=\" + start_time + \"%2000:00%20to%20\" + )\n",
    "            \n",
    "    #        urls.append(url)\n",
    "    #    except Exception as e:\n",
    "    #        print(e)\n",
    "    \n",
    "    ####################################\n",
    "    elif variable_name == 'DA_LMP_PJM'or variable_name == 'RT_LMP_PJM':  \n",
    "        try:\n",
    "            start_time_list = start_time.split('-')\n",
    "            end_time_list = end_time.split('-')\n",
    "            d0 = date(int(start_time_list[0]), int(start_time_list[1]), int(start_time_list[2]))\n",
    "            d1 = date(int(end_time_list[0]), int(end_time_list[1]), int(end_time_list[2]))\n",
    "            \n",
    "            if variable_name == 'DA_LMP_PJM':#increase download threadhold\n",
    "                days_num = 300\n",
    "            else:\n",
    "                days_num = 150\n",
    "            \n",
    "            date_var_list = date_range_list(d0, d1, days_num= days_num)\n",
    "            urls = []\n",
    "            iter_num = 0\n",
    "            for i_date in date_var_list:\n",
    "                #print(str(i_date),iter_num)\n",
    "                if iter_num == 0:\n",
    "                    start_d = str(i_date)\n",
    "                elif iter_num != 0:\n",
    "                    end_d = str(i_date)\n",
    "                    if variable_name == 'DA_LMP_PJM':\n",
    "                        url = (\"https://api.pjm.com/api/v1/\" + variable_str +\n",
    "                                   \"?rowCount=50000&order=Asc&startRow=1&\" + variable_date_str + \n",
    "                                   \"=\" + start_d + \"%2005:00%20to%20\" + end_d + \"%2004:00\"+\"&pnode_id=1\")\n",
    "                    elif variable_name == 'RT_LMP_PJM':\n",
    "                        url = (\"https://api.pjm.com/api/v1/\" + variable_str +\n",
    "                                   \"?rowCount=50000&order=Asc&startRow=1&\" + variable_date_str + \n",
    "                                   \"=\" + start_d + \"%2005:00%20to%20\" + end_d + \"%2004:55\"+\"&pnode_id=1\")\n",
    "                    urls.append(url)\n",
    "                    start_d = str(i_date)\n",
    "                iter_num = iter_num + 1\n",
    "            #urls.append(url)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    ####################################\n",
    "    else:  \n",
    "        try:\n",
    "            start_time_list = start_time.split('-')\n",
    "            end_time_list = end_time.split('-')\n",
    "            d0 = date(int(start_time_list[0]), int(start_time_list[1]), int(start_time_list[2]))\n",
    "            d1 = date(int(end_time_list[0]), int(end_time_list[1]), int(end_time_list[2]))\n",
    "            if variable_name == 'DA_LMP_PJM':\n",
    "                days_num = 30\n",
    "            elif variable_name == 'RT_LMP_PJM':\n",
    "                days_num = 7\n",
    "            elif variable_name == 'outage_forecast_daily_PJM':\n",
    "                days_num = 300\n",
    "            date_var_list = date_range_list(d0, d1, days_num=days_num)\n",
    "            urls = []\n",
    "            iter_num = 0\n",
    "            for i_date in date_var_list:\n",
    "                #print(str(i_date),iter_num)\n",
    "                if iter_num == 0:\n",
    "                    start_d = str(i_date)\n",
    "                elif iter_num != 0:\n",
    "                    end_d = str(i_date)\n",
    "                    if variable_name == 'outage_forecast_daily_PJM':\n",
    "                        url = (\"https://api.pjm.com/api/v1/\" + variable_str +\n",
    "                               \"?rowCount=50000&order=Asc&startRow=1&\" + variable_date_str + \n",
    "                               \"=\" + start_d + \"%2000:00%20to%20\" + end_d + \"%2023:00\")\n",
    "                    else:\n",
    "                        url = (\"https://api.pjm.com/api/v1/\" + variable_str +\n",
    "                               \"?rowCount=50000&order=Asc&startRow=1&\" + variable_date_str + \n",
    "                               \"=\" + start_d + \"%2005:00%20to%20\" + end_d + \"%2004:00\")\n",
    "                    print(url)\n",
    "                    urls.append(url)\n",
    "                    start_d = str(i_date)\n",
    "                iter_num = iter_num + 1\n",
    "            \n",
    "            #urls.append(url)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    ####################################\n",
    "    for i_url, url in enumerate(urls):\n",
    "        #time.sleep(random.randint(1, 5))\n",
    "        req = urllib.request.Request(url, headers=hdr)\n",
    "        req.get_method = lambda: 'GET'\n",
    "        response = urllib.request.urlopen(req)\n",
    "        print(response.getcode())\n",
    "        results = response.read()\n",
    "        json_data = json.loads(results.decode('utf-8'))\n",
    "        print(url)\n",
    "        df_results_1 = pd.DataFrame(json_data['items'])\n",
    "        print(df_results_1)\n",
    "        if i_url % 4 == 0 and i_url!=0:#the whole loop used to reset the PJM api call\n",
    "            time.sleep(random.randint(60, 62)) #take a sleep to make it like human bechavior\n",
    "            url_random = \"https://api.pjm.com/api/v1/load_frcstd_hist?rowCount=50000&order=Asc&startRow=1\"\n",
    "            req = urllib.request.Request(url_random, headers=hdr)#take a random api call to reset the count\n",
    "            req.get_method = lambda: 'GET'\n",
    "            response = urllib.request.urlopen(req)\n",
    "            print('Reset the api count')\n",
    "        df_results = pd.concat([df_results,df_results_1], ignore_index=True)\n",
    "    #print(df_results)\n",
    "    \n",
    "    return df_results\n",
    "df_results = pjm_data_downloading(start_time, end_time, variable_name, info_dict_PJM)\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49875018-fb42-4fbe-a194-6900ae90530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\"H:/BatteryStart/Dashboard/DATA/Griddata/outage_forecast_daily_PJM.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f417d473-d40a-4330-8c90-92d29063571b",
   "metadata": {},
   "source": [
    "## 2. Processing Example\n",
    "Aim to get the best availible demand forecast and insert real demand data if the forecast data are missing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b457da1-da5c-43b2-bbaa-d539155d6dab",
   "metadata": {},
   "source": [
    "### 2.1. Demand Forecast Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6b7716c-3946-45c6-bce9-a0d0b7117877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                evaluated_at_utc     evaluated_at_ept  \\\n",
      "forecast_hour_beginning_utc                                             \n",
      "2024-01-01T05:00:00          2023-12-31T14:45:00  2023-12-31T09:45:00   \n",
      "2024-01-01T06:00:00          2023-12-31T14:45:00  2023-12-31T09:45:00   \n",
      "2024-01-01T07:00:00          2023-12-31T14:45:00  2023-12-31T09:45:00   \n",
      "2024-01-01T08:00:00          2023-12-31T14:45:00  2023-12-31T09:45:00   \n",
      "2024-01-01T09:00:00          2023-12-31T14:45:00  2023-12-31T09:45:00   \n",
      "...                                          ...                  ...   \n",
      "2025-09-30T19:00:00          2025-09-29T13:45:00  2025-09-29T09:45:00   \n",
      "2025-09-30T20:00:00          2025-09-29T13:45:00  2025-09-29T09:45:00   \n",
      "2025-09-30T21:00:00          2025-09-29T13:45:00  2025-09-29T09:45:00   \n",
      "2025-09-30T22:00:00          2025-09-29T13:45:00  2025-09-29T09:45:00   \n",
      "2025-09-30T23:00:00          2025-09-29T13:45:00  2025-09-29T09:45:00   \n",
      "\n",
      "                            forecast_hour_beginning_ept  AEP_mw  EKPC_mw  \\\n",
      "forecast_hour_beginning_utc                                                \n",
      "2024-01-01T05:00:00                 2024-01-01T00:00:00   14165     1885   \n",
      "2024-01-01T06:00:00                 2024-01-01T01:00:00   13929     1902   \n",
      "2024-01-01T07:00:00                 2024-01-01T02:00:00   13782     1901   \n",
      "2024-01-01T08:00:00                 2024-01-01T03:00:00   13803     1911   \n",
      "2024-01-01T09:00:00                 2024-01-01T04:00:00   13878     1923   \n",
      "...                                                 ...     ...      ...   \n",
      "2025-09-30T19:00:00                 2025-09-30T15:00:00   19061     2024   \n",
      "2025-09-30T20:00:00                 2025-09-30T16:00:00   19343     2119   \n",
      "2025-09-30T21:00:00                 2025-09-30T17:00:00   19448     2132   \n",
      "2025-09-30T22:00:00                 2025-09-30T18:00:00   19128     2055   \n",
      "2025-09-30T23:00:00                 2025-09-30T19:00:00   18641     1949   \n",
      "\n",
      "                             ATSI_mw  DEOK_mw  APS_mw  RTO_mw  DAY_mw  DUQ_mw  \\\n",
      "forecast_hour_beginning_utc                                                     \n",
      "2024-01-01T05:00:00           6595.0     2732  5335.0   84060  1747.0    1369   \n",
      "2024-01-01T06:00:00           6462.0     2676  5222.0   82132  1705.0    1338   \n",
      "2024-01-01T07:00:00           6355.0     2650  5175.0   81097  1683.0    1317   \n",
      "2024-01-01T08:00:00           6329.0     2638  5183.0   80822  1674.0    1306   \n",
      "2024-01-01T09:00:00           6352.0     2655  5221.0   81269  1680.0    1309   \n",
      "...                              ...      ...     ...     ...     ...     ...   \n",
      "2025-09-30T19:00:00           9018.0     4018  6443.0  109590  2624.0    1875   \n",
      "2025-09-30T20:00:00           9112.0     4077  6546.0  111528  2672.0    1910   \n",
      "2025-09-30T21:00:00           9089.0     4085  6582.0  111993  2687.0    1889   \n",
      "2025-09-30T22:00:00           8912.0     3975  6451.0  110244  2618.0    1823   \n",
      "2025-09-30T23:00:00           8691.0     3811  6335.0  107653  2509.0    1762   \n",
      "\n",
      "                             DOM_mw  COMED_mw  MIDATL_mw  \n",
      "forecast_hour_beginning_utc                               \n",
      "2024-01-01T05:00:00           13459      9580    27193.0  \n",
      "2024-01-01T06:00:00           13287      9257    26354.0  \n",
      "2024-01-01T07:00:00           13262      9044    25928.0  \n",
      "2024-01-01T08:00:00           13302      8916    25760.0  \n",
      "2024-01-01T09:00:00           13477      8857    25917.0  \n",
      "...                             ...       ...        ...  \n",
      "2025-09-30T19:00:00           15719     14528    34280.0  \n",
      "2025-09-30T20:00:00           15963     14626    35160.0  \n",
      "2025-09-30T21:00:00           15997     14550    35534.0  \n",
      "2025-09-30T22:00:00           16030     14111    35141.0  \n",
      "2025-09-30T23:00:00           15843     13468    34644.0  \n",
      "\n",
      "[15331 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta,date\n",
    "import urllib.request, json\n",
    "import numpy as np\n",
    "\n",
    "df_results = pd.read_csv(\"H:/BatteryStart/Dashboard/DATA/Griddata/demand_forecast_hourly_PJM.csv\")\n",
    "# the raw data\n",
    "def dates_bwn_two_dates(start_date, end_date):\n",
    "    '''\n",
    "    Generate dates between two given date\n",
    "    '''\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "def filter_demand_forecast(sdate, edate, df_results):\n",
    "    '''\n",
    "    filter the historal demand forecast to get the latest availible forecast before the bidding start\n",
    "    \n",
    "    sdate: start date in date format, for example, date(2024,1,1)\n",
    "    edate: end date in date format, for example, date(2025,10,1)\n",
    "    df_results: pandas dataframe \n",
    "    \n",
    "    '''\n",
    "    df_results['date'] = pd.to_datetime(df_results[\"forecast_hour_beginning_utc\"]).dt.date\n",
    "    date_timestamp_list = []\n",
    "    df_filtered = pd.DataFrame()\n",
    "    #print(dates_bwn_twodates(sdate,edate))\n",
    "    date_list = pd.date_range(sdate,edate-timedelta(days=1),freq='d')\n",
    "    for i_date in date_list:\n",
    "        i_date_yesterday = i_date-timedelta(days=1)\n",
    "        #print(i_date_yesterday)\n",
    "        i_date_str = str(i_date.date())\n",
    "        i_date_yesterday_str = str(i_date_yesterday.year) +'-' + str(i_date_yesterday.month) +'-' + str(i_date_yesterday.day) + \" 14:45:00\"\n",
    "        #print(i_date_yesterday_str)\n",
    "        target_time_date = datetime.strptime(i_date_str, \"%Y-%m-%d\")\n",
    "        target_time_yesterday_date = datetime.strptime(i_date_yesterday_str,\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        df_i_date = df_results[pd.to_datetime(df_results['date']) == target_time_date]\n",
    "        df_i_date = df_i_date[pd.to_datetime(df_i_date['evaluated_at_utc'])<=target_time_yesterday_date]\n",
    "        \n",
    "        df_filtered = pd.concat([df_filtered,df_i_date], axis = 0)\n",
    "        i_date_timestamp = df_i_date['evaluated_at_utc'].max()\n",
    "        #print(i_date_timestamp)\n",
    "        date_timestamp_list.append(i_date_timestamp)\n",
    "    df_rawdata_without_real_demand = df_filtered[df_filtered['evaluated_at_utc'].isin(date_timestamp_list)]\n",
    "    \n",
    "    return df_rawdata_without_real_demand\n",
    "\n",
    "def find_missing_demand_forecast(df_rawdata_without_real_demand):\n",
    "    '''\n",
    "    check which hour are missing from the demand forecast\n",
    "    \n",
    "    df_rawdata_without_real_demand(pandas DataFrame): the raw data with missing data as N/A or missing\n",
    "    '''\n",
    "    df_filtered = df_rawdata_without_real_demand[df_rawdata_without_real_demand['forecast_area']=='AEP'].sort_values(by=['forecast_hour_beginning_utc']).drop_duplicates(subset='forecast_hour_beginning_utc', keep='first')\n",
    "    \n",
    "    ## Find the missing hour in the dataset\n",
    "    df_AEP = df_rawdata_without_real_demand[df_rawdata_without_real_demand['forecast_area']=='AEP']\n",
    "    full_range = pd.date_range(start=pd.DatetimeIndex(df_AEP['forecast_hour_beginning_utc']).min(), end=pd.DatetimeIndex(df_AEP['forecast_hour_beginning_utc']).max(), freq=\"h\")\n",
    "    missing_hours = full_range.difference(pd.DatetimeIndex(df_AEP['forecast_hour_beginning_utc']))\n",
    "    #print(missing_hours)\n",
    "    date_str_pjm_api_call_list = []\n",
    "    #print(pd.to_missing_hours[:].date())\n",
    "    \n",
    "    ## Generate the continue date str for minized API call\n",
    "    count = 0\n",
    "    for i_time in missing_hours:\n",
    "        if count == 0:\n",
    "            start_date = i_time\n",
    "            intial_start_date = i_time\n",
    "            intial_end_date = i_time\n",
    "        \n",
    "        end_date = i_time\n",
    "        time_diff = end_date - start_date\n",
    "        #print((time_diff))\n",
    "        if time_diff > timedelta(hours=1):\n",
    "            date_str_pjm_api_call = str(intial_start_date.date())+\"%20\"+str(intial_start_date.time())+\"%20to%20\"+ str(start_date.date()) +\"%20\"+str(start_date.time())\n",
    "            intial_start_date = i_time\n",
    "            #print(date_str_pjm_api_call)\n",
    "            date_str_pjm_api_call_list.append(date_str_pjm_api_call)\n",
    "        start_date = i_time\n",
    "        if count == len(missing_hours)-1:\n",
    "            date_str_pjm_api_call = str(intial_start_date.date())+\"%20\"+str(intial_start_date.time())+\"%20to%20\"+ str(start_date.date()) +\"%20\"+str(start_date.time())\n",
    "            intial_start_date = i_time\n",
    "            #print(date_str_pjm_api_call)\n",
    "            date_str_pjm_api_call_list.append(date_str_pjm_api_call)\n",
    "        \n",
    "        count = count+1\n",
    "    return date_str_pjm_api_call_list\n",
    "\n",
    "def call_real_demand_fill_miss_demand_forecast(date_str_pjm_api_call_list):\n",
    "    '''\n",
    "    date_str_pjm_api_call_list(list): list that include date string for API call to fill missing demand forecast data. \n",
    "                                It looks like ['2024-01-21%2005:00:00%20to%202024-01-21%2012:00:00', '2024-03-10%2005:00:00%20to%202024-03-10%2011:00:00', '2024-06-29%2004:00:00%20to%202024-06-29%2011:00:00', '2025-03-09%2005:00:00%20to%202025-03-09%2011:00:00']\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    df_miss_data = pd.DataFrame()\n",
    "    df_with_real_data_as_missing = pd.DataFrame()\n",
    "    for i_call in date_str_pjm_api_call_list:\n",
    "        try:\n",
    "            url = \"https://api.pjm.com/api/v1/hrl_load_estimated?rowCount=50000&startRow=1&datetime_beginning_utc=\" + i_call\n",
    "            #2024-01-21%2005:00:00%20to%202024-01-21%2012:00:00\"\n",
    "        \n",
    "            hdr ={\n",
    "            # Request headers\n",
    "            'Cache-Control': 'no-cache',\n",
    "            'Ocp-Apim-Subscription-Key': '336423db3cd243a3841d772330f22cc7',\n",
    "            }\n",
    "            req = urllib.request.Request(url, headers=hdr)\n",
    "            req.get_method = lambda: 'GET'\n",
    "            response = urllib.request.urlopen(req)\n",
    "            #print(response.getcode())\n",
    "            results = response.read()\n",
    "            json_data = json.loads(results.decode('utf-8'))\n",
    "            #print(url)\n",
    "            df_results_1 = pd.DataFrame(json_data['items'])\n",
    "            #print(df_results_1)\n",
    "            \n",
    "            df_temp = df_results_1.rename(columns={\"datetime_beginning_utc\": \"forecast_hour_beginning_utc\", \n",
    "                                                   \"datetime_beginning_ept\": \"forecast_hour_beginning_ept\",\n",
    "                                                   \"load_area\": \"forecast_area\",\n",
    "                                                   \"estimated_load_hourly\": \"forecast_load_mw\",\n",
    "                                                  })#.loc()\n",
    "            \n",
    "            df_temp['evaluated_at_utc'] =  df_temp['forecast_hour_beginning_utc'] \n",
    "            df_temp['evaluated_at_ept'] =  df_temp['forecast_hour_beginning_ept']\n",
    "            df_temp= df_temp.drop(['datetime_ending_utc','datetime_ending_ept'], axis=1)\n",
    "            df_temp_groupsum = df_temp.groupby(['forecast_hour_beginning_utc','forecast_hour_beginning_ept']).sum().reset_index()\n",
    "            df_temp_groupsum['forecast_area'] = 'RTO'\n",
    "            #print(df_temp_groupsum)\n",
    "            \n",
    "            df_temp_0 = pd.concat([df_temp_groupsum['forecast_hour_beginning_utc'].rename(\"evaluated_at_utc\"),#.loc['forecast_hour_beginning_utc'],\n",
    "                                   df_temp_groupsum['forecast_hour_beginning_ept'].rename(\"evaluated_at_ept\"),\n",
    "                                   #df_temp_groupsum['forecast_hour_beginning_utc'],\n",
    "                                   df_temp_groupsum['forecast_hour_beginning_utc'],\n",
    "                                   df_temp_groupsum['forecast_hour_beginning_ept'], \n",
    "                                   df_temp_groupsum['forecast_area'],\n",
    "                                   df_temp_groupsum['forecast_load_mw']], axis=1)\n",
    "    \n",
    "            df_temp = pd.concat([df_temp,df_temp_0], axis = 0)\n",
    "            df_miss_data = pd.concat([df_miss_data,df_temp], axis = 0)\n",
    "            #print(df_miss_data)\n",
    "            #df_results_1.to_csv('H:/BatteryStart/Dashboard/DATA/Griddata/real_demand.csv')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return df_miss_data\n",
    "\n",
    "def download_demand_forecast_with_missing_data_filling(sdate, edate, df_results):\n",
    "    '''\n",
    "    make the oraginal dataframe to \n",
    "    \n",
    "    sdate: start date in date format, for example, date(2024,1,1)\n",
    "    edate: end date in date format, for example, date(2025,10,1)\n",
    "    df_results: pandas dataframe, \n",
    "    \n",
    "    '''\n",
    "    area_drop_list_for_real_demand = ['PJME', 'PJMW', 'DAYTON', 'FE']\n",
    "    \n",
    "    df_rawdata_without_real_demand = filter_demand_forecast(sdate, edate, df_results)\n",
    "    date_str_pjm_api_call_list = find_missing_demand_forecast(df_rawdata_without_real_demand)\n",
    "    df_miss_data = call_real_demand_fill_miss_demand_forecast(date_str_pjm_api_call_list)\n",
    "\n",
    "    df_with_real_data_as_missing = pd.concat([df_rawdata_without_real_demand.drop_duplicates(subset=['forecast_hour_beginning_utc','forecast_area'], \n",
    "                                                                         keep='first'),df_miss_data], axis = 0).sort_values(by=['forecast_hour_beginning_utc'])\n",
    "    df_with_real_data_as_missing = df_with_real_data_as_missing[~df_with_real_data_as_missing['forecast_area'].isin(area_drop_list_for_real_demand)]\n",
    "    #print('df_with_real_data_as_missing:',df_with_real_data_as_missing)\n",
    "    \n",
    "    unique_area = df_with_real_data_as_missing['forecast_area'].unique()\n",
    "    \n",
    "    count_area = 0\n",
    "    for i_area in unique_area:    \n",
    "        \n",
    "        df_i_area = df_with_real_data_as_missing[df_with_real_data_as_missing['forecast_area']==i_area]\n",
    "        \n",
    "        if count_area!=0:\n",
    "            df_i_area = df_i_area.drop(['forecast_area','date','evaluated_at_utc','evaluated_at_ept','forecast_hour_beginning_ept'], axis=1).rename(columns = {'forecast_load_mw':(i_area+'_mw')})#.set_index('forecast_hour_beginning_utc', inplace=True)    \n",
    "            df_i_area.set_index('forecast_hour_beginning_utc', inplace=True)\n",
    "            #df_forecast_load_area = pd.merge(df_forecast_load_area,df_i_area,on='forecast_hour_beginning_utc')\n",
    "            #df_forecast_load_area = df_forecast_load_area.join(df_i_area,on = 'forecast_hour_beginning_utc')#how='outer'\n",
    "            df_forecast_load_area = pd.concat([df_forecast_load_area,df_i_area],axis=1)\n",
    "        else:\n",
    "            df_i_area = df_i_area.drop(['forecast_area','date'], axis=1).rename(columns = {'forecast_load_mw':(i_area+'_mw')})\n",
    "            df_i_area.set_index('forecast_hour_beginning_utc', inplace=True)\n",
    "            df_forecast_load_area = df_i_area\n",
    "            \n",
    "        #print(df_i_area)\n",
    "        count_area = count_area + 1\n",
    "    \n",
    "    df_forecast_load_area.fillna(0, inplace=True)## replace the data which still miss as 0\n",
    "    \n",
    "    return df_forecast_load_area\n",
    "\n",
    "### example usage\n",
    "df_results = pd.read_csv(\"H:/BatteryStart/Dashboard/DATA/Griddata/demand_forecast_hourly_PJM.csv\")\n",
    "sdate = date(2024,1,1)\n",
    "edate = date(2025,10,1)\n",
    "\n",
    "df_forecast_load_area = download_demand_forecast_with_missing_data_filling(sdate, edate, df_results)\n",
    "print(df_forecast_load_area)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef57999-6fef-4604-bc6a-72fc61c7839a",
   "metadata": {},
   "source": [
    "### 2.2. Outage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "45303bbb-e05e-48da-bc15-12c02cb950af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-01 00:00:00\n",
      "2024-01-02 00:00:00\n",
      "2024-01-03 00:00:00\n",
      "2024-01-04 00:00:00\n",
      "2024-01-05 00:00:00\n",
      "2024-01-06 00:00:00\n",
      "2024-01-07 00:00:00\n",
      "2024-01-08 00:00:00\n",
      "2024-01-09 00:00:00\n",
      "2024-01-10 00:00:00\n",
      "2024-01-11 00:00:00\n",
      "2024-01-12 00:00:00\n",
      "2024-01-13 00:00:00\n",
      "2024-01-14 00:00:00\n",
      "2024-01-15 00:00:00\n",
      "2024-01-16 00:00:00\n",
      "2024-01-17 00:00:00\n",
      "2024-01-18 00:00:00\n",
      "2024-01-19 00:00:00\n",
      "2024-01-20 00:00:00\n",
      "2024-01-21 00:00:00\n",
      "2024-01-22 00:00:00\n",
      "2024-01-23 00:00:00\n",
      "2024-01-24 00:00:00\n",
      "2024-01-25 00:00:00\n",
      "2024-01-26 00:00:00\n",
      "2024-01-27 00:00:00\n",
      "2024-01-28 00:00:00\n",
      "2024-01-29 00:00:00\n",
      "2024-01-30 00:00:00\n",
      "2024-01-31 00:00:00\n",
      "2024-02-01 00:00:00\n",
      "2024-02-02 00:00:00\n",
      "2024-02-03 00:00:00\n",
      "2024-02-04 00:00:00\n",
      "2024-02-05 00:00:00\n",
      "2024-02-06 00:00:00\n",
      "2024-02-07 00:00:00\n",
      "2024-02-08 00:00:00\n",
      "2024-02-09 00:00:00\n",
      "2024-02-10 00:00:00\n",
      "2024-02-11 00:00:00\n",
      "2024-02-12 00:00:00\n",
      "2024-02-13 00:00:00\n",
      "2024-02-14 00:00:00\n",
      "2024-02-15 00:00:00\n",
      "2024-02-16 00:00:00\n",
      "2024-02-17 00:00:00\n",
      "2024-02-18 00:00:00\n",
      "2024-02-19 00:00:00\n",
      "2024-02-20 00:00:00\n",
      "2024-02-21 00:00:00\n",
      "2024-02-22 00:00:00\n",
      "2024-02-23 00:00:00\n",
      "2024-02-24 00:00:00\n",
      "2024-02-25 00:00:00\n",
      "2024-02-26 00:00:00\n",
      "2024-02-27 00:00:00\n",
      "2024-02-28 00:00:00\n",
      "2024-02-29 00:00:00\n",
      "2024-03-01 00:00:00\n",
      "2024-03-02 00:00:00\n",
      "2024-03-03 00:00:00\n",
      "2024-03-04 00:00:00\n",
      "2024-03-05 00:00:00\n",
      "2024-03-06 00:00:00\n",
      "2024-03-07 00:00:00\n",
      "2024-03-08 00:00:00\n",
      "2024-03-09 00:00:00\n",
      "2024-03-10 00:00:00\n",
      "2024-03-11 00:00:00\n",
      "2024-03-12 00:00:00\n",
      "2024-03-13 00:00:00\n",
      "2024-03-14 00:00:00\n",
      "2024-03-15 00:00:00\n",
      "2024-03-16 00:00:00\n",
      "2024-03-17 00:00:00\n",
      "2024-03-18 00:00:00\n",
      "2024-03-19 00:00:00\n",
      "2024-03-20 00:00:00\n",
      "2024-03-21 00:00:00\n",
      "2024-03-22 00:00:00\n",
      "2024-03-23 00:00:00\n",
      "2024-03-24 00:00:00\n",
      "2024-03-25 00:00:00\n",
      "2024-03-26 00:00:00\n",
      "2024-03-27 00:00:00\n",
      "2024-03-28 00:00:00\n",
      "2024-03-29 00:00:00\n",
      "2024-03-30 00:00:00\n",
      "2024-03-31 00:00:00\n",
      "2024-04-01 00:00:00\n",
      "2024-04-02 00:00:00\n",
      "2024-04-03 00:00:00\n",
      "2024-04-04 00:00:00\n",
      "2024-04-05 00:00:00\n",
      "2024-04-06 00:00:00\n",
      "2024-04-07 00:00:00\n",
      "2024-04-08 00:00:00\n",
      "2024-04-09 00:00:00\n",
      "2024-04-10 00:00:00\n",
      "2024-04-11 00:00:00\n",
      "2024-04-12 00:00:00\n",
      "2024-04-13 00:00:00\n",
      "2024-04-14 00:00:00\n",
      "2024-04-15 00:00:00\n",
      "2024-04-16 00:00:00\n",
      "2024-04-17 00:00:00\n",
      "2024-04-18 00:00:00\n",
      "2024-04-19 00:00:00\n",
      "2024-04-20 00:00:00\n",
      "2024-04-21 00:00:00\n",
      "2024-04-22 00:00:00\n",
      "2024-04-23 00:00:00\n",
      "2024-04-24 00:00:00\n",
      "2024-04-25 00:00:00\n",
      "2024-04-26 00:00:00\n",
      "2024-04-27 00:00:00\n",
      "2024-04-28 00:00:00\n",
      "2024-04-29 00:00:00\n",
      "2024-04-30 00:00:00\n",
      "2024-05-01 00:00:00\n",
      "2024-05-02 00:00:00\n",
      "2024-05-03 00:00:00\n",
      "2024-05-04 00:00:00\n",
      "2024-05-05 00:00:00\n",
      "2024-05-06 00:00:00\n",
      "2024-05-07 00:00:00\n",
      "2024-05-08 00:00:00\n",
      "2024-05-09 00:00:00\n",
      "2024-05-10 00:00:00\n",
      "2024-05-11 00:00:00\n",
      "2024-05-12 00:00:00\n",
      "2024-05-13 00:00:00\n",
      "2024-05-14 00:00:00\n",
      "2024-05-15 00:00:00\n",
      "2024-05-16 00:00:00\n",
      "2024-05-17 00:00:00\n",
      "2024-05-18 00:00:00\n",
      "2024-05-19 00:00:00\n",
      "2024-05-20 00:00:00\n",
      "2024-05-21 00:00:00\n",
      "2024-05-22 00:00:00\n",
      "2024-05-23 00:00:00\n",
      "2024-05-24 00:00:00\n",
      "2024-05-25 00:00:00\n",
      "2024-05-26 00:00:00\n",
      "2024-05-27 00:00:00\n",
      "2024-05-28 00:00:00\n",
      "2024-05-29 00:00:00\n",
      "2024-05-30 00:00:00\n",
      "2024-05-31 00:00:00\n",
      "2024-06-01 00:00:00\n",
      "2024-06-02 00:00:00\n",
      "2024-06-03 00:00:00\n",
      "2024-06-04 00:00:00\n",
      "2024-06-05 00:00:00\n",
      "2024-06-06 00:00:00\n",
      "2024-06-07 00:00:00\n",
      "2024-06-08 00:00:00\n",
      "2024-06-09 00:00:00\n",
      "2024-06-10 00:00:00\n",
      "2024-06-11 00:00:00\n",
      "2024-06-12 00:00:00\n",
      "2024-06-13 00:00:00\n",
      "2024-06-14 00:00:00\n",
      "2024-06-15 00:00:00\n",
      "2024-06-16 00:00:00\n",
      "2024-06-17 00:00:00\n",
      "2024-06-18 00:00:00\n",
      "2024-06-19 00:00:00\n",
      "2024-06-20 00:00:00\n",
      "2024-06-21 00:00:00\n",
      "2024-06-22 00:00:00\n",
      "2024-06-23 00:00:00\n",
      "2024-06-24 00:00:00\n",
      "2024-06-25 00:00:00\n",
      "2024-06-26 00:00:00\n",
      "2024-06-27 00:00:00\n",
      "2024-06-28 00:00:00\n",
      "2024-06-29 00:00:00\n",
      "2024-06-30 00:00:00\n",
      "2024-07-01 00:00:00\n",
      "2024-07-02 00:00:00\n",
      "2024-07-03 00:00:00\n",
      "2024-07-04 00:00:00\n",
      "2024-07-05 00:00:00\n",
      "2024-07-06 00:00:00\n",
      "2024-07-07 00:00:00\n",
      "2024-07-08 00:00:00\n",
      "2024-07-09 00:00:00\n",
      "2024-07-10 00:00:00\n",
      "2024-07-11 00:00:00\n",
      "2024-07-12 00:00:00\n",
      "2024-07-13 00:00:00\n",
      "2024-07-14 00:00:00\n",
      "2024-07-15 00:00:00\n",
      "2024-07-16 00:00:00\n",
      "2024-07-17 00:00:00\n",
      "2024-07-18 00:00:00\n",
      "2024-07-19 00:00:00\n",
      "2024-07-20 00:00:00\n",
      "2024-07-21 00:00:00\n",
      "2024-07-22 00:00:00\n",
      "2024-07-23 00:00:00\n",
      "2024-07-24 00:00:00\n",
      "2024-07-25 00:00:00\n",
      "2024-07-26 00:00:00\n",
      "2024-07-27 00:00:00\n",
      "2024-07-28 00:00:00\n",
      "2024-07-29 00:00:00\n",
      "2024-07-30 00:00:00\n",
      "2024-07-31 00:00:00\n",
      "2024-08-01 00:00:00\n",
      "2024-08-02 00:00:00\n",
      "2024-08-03 00:00:00\n",
      "2024-08-04 00:00:00\n",
      "2024-08-05 00:00:00\n",
      "2024-08-06 00:00:00\n",
      "2024-08-07 00:00:00\n",
      "2024-08-08 00:00:00\n",
      "2024-08-09 00:00:00\n",
      "2024-08-10 00:00:00\n",
      "2024-08-11 00:00:00\n",
      "2024-08-12 00:00:00\n",
      "2024-08-13 00:00:00\n",
      "2024-08-14 00:00:00\n",
      "2024-08-15 00:00:00\n",
      "2024-08-16 00:00:00\n",
      "2024-08-17 00:00:00\n",
      "2024-08-18 00:00:00\n",
      "2024-08-19 00:00:00\n",
      "2024-08-20 00:00:00\n",
      "2024-08-21 00:00:00\n",
      "2024-08-22 00:00:00\n",
      "2024-08-23 00:00:00\n",
      "2024-08-24 00:00:00\n",
      "2024-08-25 00:00:00\n",
      "2024-08-26 00:00:00\n",
      "2024-08-27 00:00:00\n",
      "2024-08-28 00:00:00\n",
      "2024-08-29 00:00:00\n",
      "2024-08-30 00:00:00\n",
      "2024-08-31 00:00:00\n",
      "2024-09-01 00:00:00\n",
      "2024-09-02 00:00:00\n",
      "2024-09-03 00:00:00\n",
      "2024-09-04 00:00:00\n",
      "2024-09-05 00:00:00\n",
      "2024-09-06 00:00:00\n",
      "2024-09-07 00:00:00\n",
      "2024-09-08 00:00:00\n",
      "2024-09-09 00:00:00\n",
      "2024-09-10 00:00:00\n",
      "2024-09-11 00:00:00\n",
      "2024-09-12 00:00:00\n",
      "2024-09-13 00:00:00\n",
      "2024-09-14 00:00:00\n",
      "2024-09-15 00:00:00\n",
      "2024-09-16 00:00:00\n",
      "2024-09-17 00:00:00\n",
      "2024-09-18 00:00:00\n",
      "2024-09-19 00:00:00\n",
      "2024-09-20 00:00:00\n",
      "2024-09-21 00:00:00\n",
      "2024-09-22 00:00:00\n",
      "2024-09-23 00:00:00\n",
      "2024-09-24 00:00:00\n",
      "2024-09-25 00:00:00\n",
      "2024-09-26 00:00:00\n",
      "2024-09-27 00:00:00\n",
      "2024-09-28 00:00:00\n",
      "2024-09-29 00:00:00\n",
      "2024-09-30 00:00:00\n",
      "2024-10-01 00:00:00\n",
      "2024-10-02 00:00:00\n",
      "2024-10-03 00:00:00\n",
      "2024-10-04 00:00:00\n",
      "2024-10-05 00:00:00\n",
      "2024-10-06 00:00:00\n",
      "2024-10-07 00:00:00\n",
      "2024-10-08 00:00:00\n",
      "2024-10-09 00:00:00\n",
      "2024-10-10 00:00:00\n",
      "2024-10-11 00:00:00\n",
      "2024-10-12 00:00:00\n",
      "2024-10-13 00:00:00\n",
      "2024-10-14 00:00:00\n",
      "2024-10-15 00:00:00\n",
      "2024-10-16 00:00:00\n",
      "2024-10-17 00:00:00\n",
      "2024-10-18 00:00:00\n",
      "2024-10-19 00:00:00\n",
      "2024-10-20 00:00:00\n",
      "2024-10-21 00:00:00\n",
      "2024-10-22 00:00:00\n",
      "2024-10-23 00:00:00\n",
      "2024-10-24 00:00:00\n",
      "2024-10-25 00:00:00\n",
      "2024-10-26 00:00:00\n",
      "2024-10-27 00:00:00\n",
      "2024-10-28 00:00:00\n",
      "2024-10-29 00:00:00\n",
      "2024-10-30 00:00:00\n",
      "2024-10-31 00:00:00\n",
      "2024-11-01 00:00:00\n",
      "2024-11-02 00:00:00\n",
      "2024-11-03 00:00:00\n",
      "2024-11-04 00:00:00\n",
      "2024-11-05 00:00:00\n",
      "2024-11-06 00:00:00\n",
      "2024-11-07 00:00:00\n",
      "2024-11-08 00:00:00\n",
      "2024-11-09 00:00:00\n",
      "2024-11-10 00:00:00\n",
      "2024-11-11 00:00:00\n",
      "2024-11-12 00:00:00\n",
      "2024-11-13 00:00:00\n",
      "2024-11-14 00:00:00\n",
      "2024-11-15 00:00:00\n",
      "2024-11-16 00:00:00\n",
      "2024-11-17 00:00:00\n",
      "2024-11-18 00:00:00\n",
      "2024-11-19 00:00:00\n",
      "2024-11-20 00:00:00\n",
      "2024-11-21 00:00:00\n",
      "2024-11-22 00:00:00\n",
      "2024-11-23 00:00:00\n",
      "2024-11-24 00:00:00\n",
      "2024-11-25 00:00:00\n",
      "2024-11-26 00:00:00\n",
      "2024-11-27 00:00:00\n",
      "2024-11-28 00:00:00\n",
      "2024-11-29 00:00:00\n",
      "2024-11-30 00:00:00\n",
      "2024-12-01 00:00:00\n",
      "2024-12-02 00:00:00\n",
      "2024-12-03 00:00:00\n",
      "2024-12-04 00:00:00\n",
      "2024-12-05 00:00:00\n",
      "2024-12-06 00:00:00\n",
      "2024-12-07 00:00:00\n",
      "2024-12-08 00:00:00\n",
      "2024-12-09 00:00:00\n",
      "2024-12-10 00:00:00\n",
      "2024-12-11 00:00:00\n",
      "2024-12-12 00:00:00\n",
      "2024-12-13 00:00:00\n",
      "2024-12-14 00:00:00\n",
      "2024-12-15 00:00:00\n",
      "2024-12-16 00:00:00\n",
      "2024-12-17 00:00:00\n",
      "2024-12-18 00:00:00\n",
      "2024-12-19 00:00:00\n",
      "2024-12-20 00:00:00\n",
      "2024-12-21 00:00:00\n",
      "2024-12-22 00:00:00\n",
      "2024-12-23 00:00:00\n",
      "2024-12-24 00:00:00\n",
      "2024-12-25 00:00:00\n",
      "2024-12-26 00:00:00\n",
      "2024-12-27 00:00:00\n",
      "2024-12-28 00:00:00\n",
      "2024-12-29 00:00:00\n",
      "2024-12-30 00:00:00\n",
      "2024-12-31 00:00:00\n",
      "2025-01-01 00:00:00\n",
      "2025-01-02 00:00:00\n",
      "2025-01-03 00:00:00\n",
      "2025-01-04 00:00:00\n",
      "2025-01-05 00:00:00\n",
      "2025-01-06 00:00:00\n",
      "2025-01-07 00:00:00\n",
      "2025-01-08 00:00:00\n",
      "2025-01-09 00:00:00\n",
      "2025-01-10 00:00:00\n",
      "2025-01-11 00:00:00\n",
      "2025-01-12 00:00:00\n",
      "2025-01-13 00:00:00\n",
      "2025-01-14 00:00:00\n",
      "2025-01-15 00:00:00\n",
      "2025-01-16 00:00:00\n",
      "2025-01-17 00:00:00\n",
      "2025-01-18 00:00:00\n",
      "2025-01-19 00:00:00\n",
      "2025-01-20 00:00:00\n",
      "2025-01-21 00:00:00\n",
      "2025-01-22 00:00:00\n",
      "2025-01-23 00:00:00\n",
      "2025-01-24 00:00:00\n",
      "2025-01-25 00:00:00\n",
      "2025-01-26 00:00:00\n",
      "2025-01-27 00:00:00\n",
      "2025-01-28 00:00:00\n",
      "2025-01-29 00:00:00\n",
      "2025-01-30 00:00:00\n",
      "2025-01-31 00:00:00\n",
      "2025-02-01 00:00:00\n",
      "2025-02-02 00:00:00\n",
      "2025-02-03 00:00:00\n",
      "2025-02-04 00:00:00\n",
      "2025-02-05 00:00:00\n",
      "2025-02-06 00:00:00\n",
      "2025-02-07 00:00:00\n",
      "2025-02-08 00:00:00\n",
      "2025-02-09 00:00:00\n",
      "2025-02-10 00:00:00\n",
      "2025-02-11 00:00:00\n",
      "2025-02-12 00:00:00\n",
      "2025-02-13 00:00:00\n",
      "2025-02-14 00:00:00\n",
      "2025-02-15 00:00:00\n",
      "2025-02-16 00:00:00\n",
      "2025-02-17 00:00:00\n",
      "2025-02-18 00:00:00\n",
      "2025-02-19 00:00:00\n",
      "2025-02-20 00:00:00\n",
      "2025-02-21 00:00:00\n",
      "2025-02-22 00:00:00\n",
      "2025-02-23 00:00:00\n",
      "2025-02-24 00:00:00\n",
      "2025-02-25 00:00:00\n",
      "2025-02-26 00:00:00\n",
      "2025-02-27 00:00:00\n",
      "2025-02-28 00:00:00\n",
      "2025-03-01 00:00:00\n",
      "2025-03-02 00:00:00\n",
      "2025-03-03 00:00:00\n",
      "2025-03-04 00:00:00\n",
      "2025-03-05 00:00:00\n",
      "2025-03-06 00:00:00\n",
      "2025-03-07 00:00:00\n",
      "2025-03-08 00:00:00\n",
      "2025-03-09 00:00:00\n",
      "2025-03-10 00:00:00\n",
      "2025-03-11 00:00:00\n",
      "2025-03-12 00:00:00\n",
      "2025-03-13 00:00:00\n",
      "2025-03-14 00:00:00\n",
      "2025-03-15 00:00:00\n",
      "2025-03-16 00:00:00\n",
      "2025-03-17 00:00:00\n",
      "2025-03-18 00:00:00\n",
      "2025-03-19 00:00:00\n",
      "2025-03-20 00:00:00\n",
      "2025-03-21 00:00:00\n",
      "2025-03-22 00:00:00\n",
      "2025-03-23 00:00:00\n",
      "2025-03-24 00:00:00\n",
      "2025-03-25 00:00:00\n",
      "2025-03-26 00:00:00\n",
      "2025-03-27 00:00:00\n",
      "2025-03-28 00:00:00\n",
      "2025-03-29 00:00:00\n",
      "2025-03-30 00:00:00\n",
      "2025-03-31 00:00:00\n",
      "2025-04-01 00:00:00\n",
      "2025-04-02 00:00:00\n",
      "2025-04-03 00:00:00\n",
      "2025-04-04 00:00:00\n",
      "2025-04-05 00:00:00\n",
      "2025-04-06 00:00:00\n",
      "2025-04-07 00:00:00\n",
      "2025-04-08 00:00:00\n",
      "2025-04-09 00:00:00\n",
      "2025-04-10 00:00:00\n",
      "2025-04-11 00:00:00\n",
      "2025-04-12 00:00:00\n",
      "2025-04-13 00:00:00\n",
      "2025-04-14 00:00:00\n",
      "2025-04-15 00:00:00\n",
      "2025-04-16 00:00:00\n",
      "2025-04-17 00:00:00\n",
      "2025-04-18 00:00:00\n",
      "2025-04-19 00:00:00\n",
      "2025-04-20 00:00:00\n",
      "2025-04-21 00:00:00\n",
      "2025-04-22 00:00:00\n",
      "2025-04-23 00:00:00\n",
      "2025-04-24 00:00:00\n",
      "2025-04-25 00:00:00\n",
      "2025-04-26 00:00:00\n",
      "2025-04-27 00:00:00\n",
      "2025-04-28 00:00:00\n",
      "2025-04-29 00:00:00\n",
      "2025-04-30 00:00:00\n",
      "2025-05-01 00:00:00\n",
      "2025-05-02 00:00:00\n",
      "2025-05-03 00:00:00\n",
      "2025-05-04 00:00:00\n",
      "2025-05-05 00:00:00\n",
      "2025-05-06 00:00:00\n",
      "2025-05-07 00:00:00\n",
      "2025-05-08 00:00:00\n",
      "2025-05-09 00:00:00\n",
      "2025-05-10 00:00:00\n",
      "2025-05-11 00:00:00\n",
      "2025-05-12 00:00:00\n",
      "2025-05-13 00:00:00\n",
      "2025-05-14 00:00:00\n",
      "2025-05-15 00:00:00\n",
      "2025-05-16 00:00:00\n",
      "2025-05-17 00:00:00\n",
      "2025-05-18 00:00:00\n",
      "2025-05-19 00:00:00\n",
      "2025-05-20 00:00:00\n",
      "2025-05-21 00:00:00\n",
      "2025-05-22 00:00:00\n",
      "2025-05-23 00:00:00\n",
      "2025-05-24 00:00:00\n",
      "2025-05-25 00:00:00\n",
      "2025-05-26 00:00:00\n",
      "2025-05-27 00:00:00\n",
      "2025-05-28 00:00:00\n",
      "2025-05-29 00:00:00\n",
      "2025-05-30 00:00:00\n",
      "2025-05-31 00:00:00\n",
      "2025-06-01 00:00:00\n",
      "2025-06-02 00:00:00\n",
      "2025-06-03 00:00:00\n",
      "2025-06-04 00:00:00\n",
      "2025-06-05 00:00:00\n",
      "2025-06-06 00:00:00\n",
      "2025-06-07 00:00:00\n",
      "2025-06-08 00:00:00\n",
      "2025-06-09 00:00:00\n",
      "2025-06-10 00:00:00\n",
      "2025-06-11 00:00:00\n",
      "2025-06-12 00:00:00\n",
      "2025-06-13 00:00:00\n",
      "2025-06-14 00:00:00\n",
      "2025-06-15 00:00:00\n",
      "2025-06-16 00:00:00\n",
      "2025-06-17 00:00:00\n",
      "2025-06-18 00:00:00\n",
      "2025-06-19 00:00:00\n",
      "2025-06-20 00:00:00\n",
      "2025-06-21 00:00:00\n",
      "2025-06-22 00:00:00\n",
      "2025-06-23 00:00:00\n",
      "2025-06-24 00:00:00\n",
      "2025-06-25 00:00:00\n",
      "2025-06-26 00:00:00\n",
      "2025-06-27 00:00:00\n",
      "2025-06-28 00:00:00\n",
      "2025-06-29 00:00:00\n",
      "2025-06-30 00:00:00\n",
      "2025-07-01 00:00:00\n",
      "2025-07-02 00:00:00\n",
      "2025-07-03 00:00:00\n",
      "2025-07-04 00:00:00\n",
      "2025-07-05 00:00:00\n",
      "2025-07-06 00:00:00\n",
      "2025-07-07 00:00:00\n",
      "2025-07-08 00:00:00\n",
      "2025-07-09 00:00:00\n",
      "2025-07-10 00:00:00\n",
      "2025-07-11 00:00:00\n",
      "2025-07-12 00:00:00\n",
      "2025-07-13 00:00:00\n",
      "2025-07-14 00:00:00\n",
      "2025-07-15 00:00:00\n",
      "2025-07-16 00:00:00\n",
      "2025-07-17 00:00:00\n",
      "2025-07-18 00:00:00\n",
      "2025-07-19 00:00:00\n",
      "2025-07-20 00:00:00\n",
      "2025-07-21 00:00:00\n",
      "2025-07-22 00:00:00\n",
      "2025-07-23 00:00:00\n",
      "2025-07-24 00:00:00\n",
      "2025-07-25 00:00:00\n",
      "2025-07-26 00:00:00\n",
      "2025-07-27 00:00:00\n",
      "2025-07-28 00:00:00\n",
      "2025-07-29 00:00:00\n",
      "2025-07-30 00:00:00\n",
      "2025-07-31 00:00:00\n",
      "2025-08-01 00:00:00\n",
      "2025-08-02 00:00:00\n",
      "2025-08-03 00:00:00\n",
      "2025-08-04 00:00:00\n",
      "2025-08-05 00:00:00\n",
      "2025-08-06 00:00:00\n",
      "2025-08-07 00:00:00\n",
      "2025-08-08 00:00:00\n",
      "2025-08-09 00:00:00\n",
      "2025-08-10 00:00:00\n",
      "2025-08-11 00:00:00\n",
      "2025-08-12 00:00:00\n",
      "2025-08-13 00:00:00\n",
      "2025-08-14 00:00:00\n",
      "2025-08-15 00:00:00\n",
      "2025-08-16 00:00:00\n",
      "2025-08-17 00:00:00\n",
      "2025-08-18 00:00:00\n",
      "2025-08-19 00:00:00\n",
      "2025-08-20 00:00:00\n",
      "2025-08-21 00:00:00\n",
      "2025-08-22 00:00:00\n",
      "2025-08-23 00:00:00\n",
      "2025-08-24 00:00:00\n",
      "2025-08-25 00:00:00\n",
      "2025-08-26 00:00:00\n",
      "2025-08-27 00:00:00\n",
      "2025-08-28 00:00:00\n",
      "2025-08-29 00:00:00\n",
      "2025-08-30 00:00:00\n",
      "2025-08-31 00:00:00\n",
      "2025-09-01 00:00:00\n",
      "2025-09-02 00:00:00\n",
      "2025-09-03 00:00:00\n",
      "2025-09-04 00:00:00\n",
      "2025-09-05 00:00:00\n",
      "2025-09-06 00:00:00\n",
      "2025-09-07 00:00:00\n",
      "2025-09-08 00:00:00\n",
      "2025-09-09 00:00:00\n",
      "2025-09-10 00:00:00\n",
      "2025-09-11 00:00:00\n",
      "2025-09-12 00:00:00\n",
      "2025-09-13 00:00:00\n",
      "2025-09-14 00:00:00\n",
      "2025-09-15 00:00:00\n",
      "2025-09-16 00:00:00\n",
      "2025-09-17 00:00:00\n",
      "2025-09-18 00:00:00\n",
      "2025-09-19 00:00:00\n",
      "2025-09-20 00:00:00\n",
      "2025-09-21 00:00:00\n",
      "2025-09-22 00:00:00\n",
      "2025-09-23 00:00:00\n",
      "2025-09-24 00:00:00\n",
      "2025-09-25 00:00:00\n",
      "2025-09-26 00:00:00\n",
      "2025-09-27 00:00:00\n",
      "2025-09-28 00:00:00\n",
      "2025-09-29 00:00:00\n",
      "2025-09-30 00:00:00\n",
      "    forecast_execution_date_ept        forecast_date  \\\n",
      "0           2023-12-31T00:00:00  2024-01-01T00:00:00   \n",
      "1           2024-01-01T00:00:00  2024-01-02T00:00:00   \n",
      "2           2024-01-02T00:00:00  2024-01-03T00:00:00   \n",
      "3           2024-01-03T00:00:00  2024-01-04T00:00:00   \n",
      "4           2024-01-04T00:00:00  2024-01-05T00:00:00   \n",
      "..                          ...                  ...   \n",
      "636         2025-09-25T00:00:00  2025-09-26T00:00:00   \n",
      "637         2025-09-26T00:00:00  2025-09-27T00:00:00   \n",
      "638         2025-09-27T00:00:00  2025-09-28T00:00:00   \n",
      "639         2025-09-28T00:00:00  2025-09-29T00:00:00   \n",
      "640         2025-09-29T00:00:00  2025-09-30T00:00:00   \n",
      "\n",
      "     forecast_gen_outage_mw_rto  forecast_gen_outage_mw_west  \\\n",
      "0                          2138                            4   \n",
      "1                          2205                           23   \n",
      "2                          2229                           23   \n",
      "3                          2205                           23   \n",
      "4                          2202                           23   \n",
      "..                          ...                          ...   \n",
      "636                       22256                        11680   \n",
      "637                       26447                        12444   \n",
      "638                       26597                        12699   \n",
      "639                       27114                        12797   \n",
      "640                       29106                        14147   \n",
      "\n",
      "     forecast_gen_outage_mw_other  \n",
      "0                            2134  \n",
      "1                            2182  \n",
      "2                            2206  \n",
      "3                            2182  \n",
      "4                            2179  \n",
      "..                            ...  \n",
      "636                         10576  \n",
      "637                         14003  \n",
      "638                         13898  \n",
      "639                         14317  \n",
      "640                         14959  \n",
      "\n",
      "[641 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta,date\n",
    "import urllib.request, json\n",
    "import numpy as np\n",
    "\n",
    "def dates_bwn_two_dates(start_date, end_date):\n",
    "    '''\n",
    "    Generate dates between two given date\n",
    "    '''\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "def filter_outage_forecast(sdate, edate, df_rawdata):\n",
    "    '''\n",
    "    filter the historal demand forecast to get the latest availible forecast before the bidding start\n",
    "    \n",
    "    sdate: start date in date format, for example, date(2024,1,1)\n",
    "    edate: end date in date format, for example, date(2025,10,1)\n",
    "    df_rawdata: pandas dataframe for the  \n",
    "    \n",
    "    '''\n",
    "    df_rawdata['date'] = pd.to_datetime(df_results[\"forecast_date\"]).dt.date\n",
    "    date_timestamp_list_forecast_execution_date = []\n",
    "    date_timestamp_list_forecast_date = []\n",
    "    df_filtered_data_outage_daily= pd.DataFrame()\n",
    "    df_filtered = pd.DataFrame()\n",
    "    date_list = pd.date_range(sdate,edate-timedelta(days=1),freq='d')\n",
    "    count_date = 0\n",
    "    for i_date in date_list:\n",
    "        i_date_yesterday = i_date-timedelta(days=1)\n",
    "        #print(i_date_yesterday)\n",
    "        i_date_str = str(i_date.date())\n",
    "        i_date_yesterday_str = str(i_date_yesterday.year) +'-' + str(i_date_yesterday.month) +'-' + str(i_date_yesterday.day) + \" 14:45:00\"\n",
    "        #print(i_date_yesterday_str)\n",
    "        target_time_date = datetime.strptime(i_date_str, \"%Y-%m-%d\")\n",
    "        target_time_yesterday_date = datetime.strptime(i_date_yesterday_str,\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        df_i_date = df_rawdata[pd.to_datetime(df_rawdata['date']) == target_time_date]\n",
    "        df_i_date = df_i_date[pd.to_datetime(df_i_date['forecast_execution_date_ept'])<=target_time_yesterday_date]\n",
    "        \n",
    "        df_filtered = pd.concat([df_filtered,df_i_date], axis = 0)\n",
    "        i_date_timestamp_forecast_execution = df_i_date['forecast_execution_date_ept'].max()\n",
    "        #print(df_filtered)\n",
    "        #print(i_date_timestamp_forecast_execution,i_date)\n",
    "        date_timestamp_list_forecast_execution_date.append(i_date_timestamp_forecast_execution)\n",
    "        date_timestamp_list_forecast_date.append(i_date)\n",
    "        print(i_date)\n",
    "        #print(type(i_date_timestamp_forecast_execution))\n",
    "        df_filtered_data_outage_i_date = df_filtered[pd.to_datetime(df_filtered['forecast_date'])==pd.to_datetime(i_date)] \n",
    "\n",
    "        #df_filtered_data_outage_i_date = df_filtered[(pd.to_datetime(df_filtered['forecast_date'])==pd.to_datetime(i_date)) and (pd.to_datetime(df_filtered['forecast_execution_date_ept'])==pd.to_datetime(i_date_timestamp_forecast_execution))] \n",
    "        #print(df_filtered_data_outage_i_date)\n",
    "        df_filtered_data_outage_i_date = df_filtered_data_outage_i_date[pd.to_datetime(df_filtered_data_outage_i_date['forecast_execution_date_ept'])==pd.to_datetime(i_date_timestamp_forecast_execution)]\n",
    "        \n",
    "        if count_date == 0:\n",
    "            df_filtered_data_outage_daily = df_filtered_data_outage_i_date\n",
    "        else:\n",
    "            df_filtered_data_outage_daily = pd.concat([df_filtered_data_outage_daily, df_filtered_data_outage_i_date], ignore_index=True)\n",
    "        count_date = count_date + 1\n",
    "        \n",
    "        df_filtered_data_outage_daily = df_filtered_data_outage_daily.drop(['Unnamed: 0','date'], axis=1)\n",
    "    return df_filtered_data_outage_daily\n",
    "\n",
    "df_rawdata_outage = pd.read_csv(\"H:/BatteryStart/Dashboard/DATA/Griddata/outage_forecast_daily_PJM.csv\")\n",
    "\n",
    "sdate = date(2024,1,1)\n",
    "edate = date(2025,10,1)\n",
    "\n",
    "\n",
    "df_filtered_data_outage_daily = filter_outage_forecast(sdate, edate, df_rawdata_outage)\n",
    "\n",
    "print(df_filtered_data_outage_daily)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6dc8b15-f047-4072-a201-3fd70a453d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        2023-10-02T00:00:00\n",
      "1        2023-10-03T00:00:00\n",
      "2        2023-10-03T00:00:00\n",
      "3        2023-10-04T00:00:00\n",
      "4        2023-10-04T00:00:00\n",
      "                ...         \n",
      "58235    2025-09-28T00:00:00\n",
      "58236    2025-09-28T00:00:00\n",
      "58237    2025-09-29T00:00:00\n",
      "58238    2025-09-29T00:00:00\n",
      "58239    2025-09-30T00:00:00\n",
      "Name: forecast_execution_date_ept, Length: 58240, dtype: object\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39304\\3709273799.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_rawdata_outage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'forecast_execution_date_ept'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_filtered_data_outage_i_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_rawdata_outage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_rawdata_outage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'forecast_execution_date_ept'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'2023-12-31T00:00:00'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf_rawdata_outage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'forecast_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'2024-01-01 00:00:00'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1578\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1579\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1580\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1581\u001b[0m             \u001b[1;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1582\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1583\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "print(df_rawdata_outage['forecast_execution_date_ept'])\n",
    "df_filtered_data_outage_i_date = df_rawdata_outage.query((pd.to_datetime(df_rawdata_outage['forecast_execution_date_ept'])=='2023-12-31T00:00:00') and (df_rawdata_outage['forecast_date']=='2024-01-01 00:00:00'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcabbe8d-1691-48e4-8adf-0619727e5717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-12-31 00:00:00')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime('2023-12-31T00:00:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd296f35-9549-40c7-83d1-94ac280f1214",
   "metadata": {},
   "source": [
    "# National Weather Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd420550-19e8-46ec-b31f-9618fb6fa8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import http.client\n",
    "from urllib.parse import urlparse\n",
    "variable_name = input('Enter the Variable Name (string): ')\n",
    "if len(variable_name) < 1:\n",
    "    variable_name = 'Temp'\n",
    "\n",
    "year_str = input('Enter the year (string): ')\n",
    "if len(year_str) < 1:\n",
    "    year_str = '2024'\n",
    "\n",
    "info_dict_NWS = {'Temp':{'variable_str':'temp','file_str': \"YEUZ98_KWBN_\"},\n",
    "    'DewPoint':{'variable_str':'td','file_str': \"YFUZ98_KWBN_\"},\n",
    "    'WindDirection':{'variable_str':'wdir','file_str': \"YBUZ98_KWBN_\"},\n",
    "    'WindSpeed':{'variable_str':'wspd','file_str': \"YCUZ98_KWBN_\"},\n",
    "    'SkyCover':{'variable_str':'sky','file_str': \"YAUZ98_KWBN_\"},\n",
    "    'RelativeHumidity':{'variable_str':'rhm','file_str': \"YRUZ98_KWBN_\"},\n",
    "    'ApparentTemp':{'variable_str':'apt','file_str': \"YTUZ98_KWBN_\"},\n",
    "    }\n",
    "\n",
    "#variable_str = info_dict_NWS[variable_name]['variable_str']\n",
    "#path_str = \"https://noaa-ndfd-pds.s3.amazonaws.com/wmo/\"+ variable_str + \"/\"\n",
    "#file_str = info_dict_NWS[variable_name]['file_str']\n",
    "\n",
    "def check_link_exists(url):\n",
    "    try:\n",
    "        parsed_url = urlparse(url)\n",
    "        conn = http.client.HTTPSConnection(parsed_url.netloc)\n",
    "        conn.request(\"HEAD\", parsed_url.path)\n",
    "        response = conn.getresponse()\n",
    "        return response.status == 200\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return False\n",
    "\n",
    "def check_file_name_previous(path_str, file_str,time_str, year_str, month_str, day_str, hour_int):#Used if the current hour's file is not exist\n",
    "    file_hour_index = 0\n",
    "    mins = 0\n",
    "    result = False\n",
    "    hour_delta = 1\n",
    "    url_index = (path_str + time_str + file_str + year_str \n",
    "                     + month_str + day_str + str(hour_int-hour_delta))\n",
    "    while result != True:\n",
    "        if mins>= 60:\n",
    "            mins = 0\n",
    "            hour_delta = hour_delta + 1\n",
    "            hour_idx = hour_int-hour_delta\n",
    "            url_index = (path_str + time_str + file_str + year_str\n",
    "                     + month_str + day_str + str(hour_idx))\n",
    "            #print(\"error\")\n",
    "            #break\n",
    "        if mins < 10:\n",
    "            mins_str = \"0\"+ str(mins)\n",
    "        else:\n",
    "            mins_str = str(mins)\n",
    "        url = url_index + mins_str\n",
    "        result = check_link_exists(url)\n",
    "        mins = mins + 1\n",
    "    file_exist_url = url_index + mins_str#str(mins-1)\n",
    "    return file_exist_url, hour_delta\n",
    "\n",
    "def check_file_name(path_str, file_str, time_str, year_str, month_str, day_str, hour_int):\n",
    "    file_hour_index = 0\n",
    "    mins = 0\n",
    "    result = False\n",
    "    url_index = (path_str + time_str + file_str + year_str \n",
    "                     + month_str + day_str + str(hour_int))\n",
    "    \n",
    "    while result != True:\n",
    "        if mins>= 60:\n",
    "            print(\"error:current hour's weather not availible\")\n",
    "            url_previous, file_hour_index = check_file_name_previous(path_str, file_str, time_str, year_str, month_str, day_str, hour_int)\n",
    "            #url_previous \n",
    "            file_exist_url = url_previous #url_index + str(mins-1)\n",
    "            return file_exist_url, file_hour_index\n",
    "            break\n",
    "        if mins < 10:\n",
    "            mins_str = \"0\"+ str(mins)\n",
    "        else:\n",
    "            mins_str = str(mins)\n",
    "        url = url_index + mins_str\n",
    "        result = check_link_exists(url)\n",
    "        mins = mins + 1\n",
    "    file_exist_url = url_index + mins_str#str(mins-1)\n",
    "    return file_exist_url, file_hour_index\n",
    "#print(check_file_name(url_index))\n",
    "\n",
    "\n",
    "def download_links_list_generation(info_dict,variable_name_str,hour_int,year_str):\n",
    "    \n",
    "    '''\n",
    "    info_dict: dict for the variable infomation list for \n",
    "    variable_name_str: which variable are downloading ('Temp','DewPoint','WindDirection','WindSpeed','SkyCover','RelativeHumidity','ApparentTemp')\n",
    "    hour_int: which hour as the reference for the forcast scan\n",
    "    year_str: which year you want downloading\n",
    "    '''\n",
    "    variable_str = info_dict[variable_name_str]['variable_str']\n",
    "    path_str = \"https://noaa-ndfd-pds.s3.amazonaws.com/wmo/\"+ variable_str + \"/\"\n",
    "    file_str = info_dict[variable_name_str]['file_str']\n",
    "    url_list = []\n",
    "    days_num_month = np.array([31,28,31,30,31,30,31,31,30,31,30,31])\n",
    "    \n",
    "    for i_month in range(12):\n",
    "        for i_day in range(days_num_month[i_month]):\n",
    "            if i_month <9:\n",
    "                month_str = '0'+str(i_month+1)\n",
    "            else:\n",
    "                month_str = str(i_month+1)\n",
    "            if i_day <9:\n",
    "                day_str = '0'+str(i_day+1)\n",
    "            else:\n",
    "                day_str = str(i_day+1)\n",
    "            time_str = year_str+'/'+ month_str +'/'+day_str+'/'\n",
    "            #url_index = (\"https://noaa-ndfd-pds.s3.amazonaws.com/wmo/temp/\" + time_str + \"YEUZ98_KWBN_\"+ year_str \n",
    "            #             + month_str + day_str + \"20\")\n",
    "            result, file_hour_index = check_file_name(path_str, file_str,time_str, year_str, month_str, day_str, hour_int)#url_index\n",
    "            print(result,file_hour_index)\n",
    "            url_list.append(result)\n",
    "            #print(check_file_name(url_index))\n",
    "    return url_list\n",
    "\n",
    "hour_int = 20\n",
    "url_list = download_links_list_generation(info_dict_NWS,variable_name,hour_int,year_str)\n",
    "print(url_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
